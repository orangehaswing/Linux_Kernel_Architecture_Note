# 锁与进程间通信

Linux作为多任务系统，能够同时运行多个进程。通常，各个进程必须尽可能保持独立。但有时候，应用程序必须彼此通信，如

- 一个进程生成的数据传输到另一个进程时；
- 数据由多个进程共享时；
- 进程必须彼此等待时；
- 需要协调资源的使用时；

## 控制机制

### 竞态条件

两种接口从外部设备读取数据。独立的数据包以不定间隔通过两个接口到达，保存在不同文件中。在文件名之后添加一个号码，表明序号：act1.file；act2.file；act3.file。该counter保存在两个进程共享的内存页中。

在一个数据包到达时，进程必须执行一些操作，才能正确保存数据

1. 从接口读取数据
2. 用序号counter构造文件名，打开一个文件
3. 将序号加1
4. 将数据写入文件，然后关闭文件

事实上，大多数情况下，上述过程都会正确运作，但在某些情况下会出错，而这也是分布式程序设计的真正困难所在。

**例子** ：

进程1从接口接收一个刚到达的新数据块。它忠实地用序号13构造文件名并打开一个文件，而同时调度器被激活并确认该进程已经消化了足够的CPU时间。必须由另一个进程替换，并且假定是进程2。要注意，此时进程1读取了counter值，但尚未对counter加1。

在进程2开始运行后，同样地从其对应的接口读取数据，并开始执行必要的操作以保存这些数据。它会读取counter的值，用序号13构造文件名打开文件，将counter加1，counter从13变为14。接下来它将数据写入文件，最后结束。

不久，又轮到进程1再次运行。它从上次暂停处恢复执行，并将counter加1，counter从14变为15。接下来它将数据写入到用序号13打开的文件。当然，这样做会覆盖进程2已经保存的数据。

几个进程在访问资源时，彼此干扰的情况通常称为竞态条件。在对分布式应用编程时，这种情况是一个主要的问题。因为竞态条件无法通过系统的试错检测。相反，只有彻底研究源代码并通过敏锐的直觉，才能找到并消除竞态条件。

### 临界区

本质：进程的执行在不应该的地方被中断，从而导致进程工作得不正确。只要没有其他的进程在临界区，那么在临界区中执行的进程完全是可以中断的。这种严格的禁止条件，可以确保几个进程不能同时改变共享的值，我们称为**互斥**。

**信号量**

信号量只是受保护的特别变量，能够表示为正负整数。其初始值为1。

为操作信号量定义了两个标准操作：up和down。这两个操作分别用于控制关键代码范围的进入和退出，且假定相互竞争的进程访问信号量机会均等。

在一个进程想要进入关键代码时，它调用down函数。这将会将信号量的值减1，即设置为0。然后执行危险代码段。在执行完操作之后，调用up函数将信号量的值加1，即重置为初始值。信号量有一下两种特性

1. 有一个进程试图进入关键代码段时，首先也必须对信号量执行down操作。因为第1个进程已经进入该代码段，信号量的值此时为0。这导致第2个进程在该信号量上睡眠。它会一直等待，直至第1个进程退出相关的代码

   执行down操作，是一个原子操作。它不能被调度器调用中断。这意味着竞态条件无法发生。从内核角度来看，查询变量的值和修改变量是两个不同的操作，但用户将二者视为一个原子操作。

2. 在进程退出关键代码时，执行up操作。这不仅会将信号量的值加1，而且还会选择一个在该信号量上睡眠的进程。该进程在恢复执行之后，完成down操作将信号量减1，此后即可安全地开始执行关键代码。

信号量在用户层可以正常工作，原则上也可以用于解决内核内部的各种锁问题。但事实上不是这样：性能是内核最首先的一个目标，虽然信号量初看起来容易实现，但其开销对内核来说过大。这也是内核中提供许多不同的锁和同步机制的原因。

## 内核锁机制

内核可以不受限制访问整个地址空间。在多处理器系统上，这会引发一些问题。如果几个处理器同时处于核心态，则理论上它们可以同时访问同一个数据结构。

内核使用由锁组成的细粒度网络，来明确地保护各个数据结构。如果处理器A在操作数据结构X，则处理器B可以执行任何其他的内核操作，但不能操作X。

内核提供的各种锁选项

- 原子操作：这些是最简单的锁操作，它们保证简单的操作，诸如计数器加1之类，可以不中断地原子执行。即使操作由几个汇编语句组成，也可以保证。
- 自旋锁：这些是最长用的锁选项。它们用于短期保护某段代码，以防止其他处理器的访问，在内核等待自旋锁释放时，会重复检查是否能获取锁，而不会进入睡眠状态(忙等待)。如果等待时间太长，则效率显然不高
- 信号量：这些是用经典方法实现的。在等待信号量释放时，内核进入睡眠状态，直至被唤醒。唤醒后，内核才重新尝试获取信号量。互斥量是信号量的特例，互斥量保护的临界区，每次只能有一个用户进入
- 读者/写者锁：这些锁会区分对数据结构的两种不同类型的访问。任意数目的处理器都可以对数据结构进行并发读访问，但只有一个处理器能进行写访问。事实上，在进行写访问时，读访问是无法进行的

### 对整数的原子操作

内核定义atomic_t数据结构，用作对整数计数器的原子操作的基础。从内核角度来看，这些操作的执行仿佛是一条汇编语句。

例子：将计数器加1

在汇编语言中，分为3步

1. 将计数器值从内存复制到处理器寄存器
2. 将其值加1
3. 将寄存器数据会写到内存

如果有另一个处理器同时执行该操作，则会发生问题。两个处理器同时从内存读取计数器的值(4)，将其加1得到5，最后将新数值回写到内存。但如果操作正确，内存中的值应该是6，因为计数器的加1操作执行了两次。

内核支持的所有处理器，都提供了原子执行此类操作的手段。一般来说，可使用特殊的锁指令阻止系统中其他处理器工作，直至当前处理器完成下一个操作为止。也可以使用效果相同的等价机制。

为使用内核中平台独立的部分能够使用原子操作，特定于体系结构的代码必须提供用于操纵atomic_t类型变量的操作。在某些系统上，这些操作与C语言中对应的普通操作相比要慢得多，因此只有在确实必要的情况下才能使用这些操作。

原子变量只能借助于ATOMIC_INIT宏初始化。因为原子数据结构最终是用普通的C语言类型实现，内核将标准类型的变量封装在结构中。

原子操作：

|                    操作                    |               效果               |
| :--------------------------------------: | :----------------------------: |
|         atomic_read(atomic_t *v)         |            读取原子变量的值            |
|     atomic_set(atomic_t *v, init i)      |             将v设置为i             |
|      atomic_add(int i, atomic_t *v)      |             将i加到v              |
|      atomic_sub(int i, atomic_t *v)      |             从v减去i              |
|  atomic_sub_return(init i, atomic_t *v)  |          从v减去i，并返回结果           |
| atomic_sub_and_test(init i, atomic_t *v) | 从v减去i，如果结果为0则返回true，否则返回false  |
|         atomic_inc(atomic_t *v)          |              将v加1              |
|     atomic_inc_and_test(atomic_t *v)     |  从v加1，如果结果为0则返回true，否则返回false  |
|         atomic_dec(atomic_t *v)          |             从v减去1              |
|     atomic_dec_and_test(atomic_t *v)     |  从v减1，如果结果为0则返回true，否则返回false  |
| atomic_add_negative(int i, atomic_t *v)  | 将i加到v，如果结果小于0则返回true，否则返回false |
| atomic_add_negative(int i, atomic_t *v)  | 将i加到v，如果结果为负则返回true，否则返回false  |

如果内核编译时为启用SMP支持，则上述操作的实现与普通变量一样，因为没有其他处理器的干扰。

内核为SMP系统提供了local_t数据类型。该类型允许在单个CPU上的原子操作。为修改此类型变量，内核提供了基本上与atomic_t数据类型相同的一组函数，只是将atomic替换为local。

注意：原子变量很适合整数操作，但不适用于比特位操作。因此每种体系结构都必须定义一组位处理操作，这些操作的工作方式也是原子的，以便在SMP系统上的各处理器之间保证一致性。

### 自旋锁

自旋锁用于保护短的代码段，其中只包含少量C语句，因此会很快执行完毕。在处理结构中的关键成员时，必须获得相应的自旋锁。

**数据结构和用法**

自旋锁通过spinlock_t数据结构实现，基本上可使用spin_lock和spin_unlock操纵。还有其他一些自旋锁操作：spin_lock_irqsave不仅获得自旋锁，还停用本地CPU的中断，而spin_lock_bh则停用softIRQ(软中断)。用这两个操作获得的自旋锁必须用对应的接口释放，分别是spin_unlock_irqsave和spin_unlock_bh。同样，自旋锁的实现也几乎是汇编语言。

用法：

```
spinlock_t lock = SPIN_LOCK_UNLOCKED;
...
spin_lock(&lock);
/* 临界区 */
spin_unlock(&lock);
```

初始化自旋锁时，必须使用SPIN_LOCK_UNLOCKED将其设置为未锁定状态。spin_lock会考虑下面两种情况

1. 如果内核中其他地方尚未获得lock，则由当前处理器获取。其他处理器不能再进入lock保护的代码范围；
2. 如果lock已经由另一个处理器获取，spin_lock进入一个无线循环，重复检查lock是否已经由spin_unlock释放。如果已经释放，则获取lock，并进入临界区；

spin_lock定义为一个原子操作，在获得自旋锁的情况下可防止竞态条件出现。

内核还提供spin_trylock和spin_trylock_bh两种方法。它们尝试获取锁，但在锁无法立即获取时不会阻塞。在锁操作成功时，它们返回非零值(代码由自旋锁保护)，否则返回0。后一种情况下，代码没有被锁保护。

使用自旋锁注意

1. 如果获得锁之后不释放，系统将会变得不可用。这产生死锁，进入无限循环等待锁释放；
2. 自旋锁决不应该长期持有，因为所有等待锁释放的处理器都处于不可用状态，无法用于其他工作；

### 信号量

内核使用的信号量

```
struct semaphore{
  atomic_t count;
  int sleepers;
  wait_queue_head_t wait;
}
```

- count指定了可以同时处于信号量保护的临界区中进程的数目。count == 1用于大多数情况
- sleepers指定了等待允许进入临界区的进程的数目。不同于自旋锁，等待的进程会进入睡眠状态，直至信号量释放才会被唤醒。这意味着相关的CPU在同时可以执行其他任务
- wait用于实现一个队列，保存所有在该信号量上睡眠的进程的task_struct

与自旋锁相比，信号量适合于保护更长的临界区，以防止并行访问。但是不应该用于保护较短的代码范围，因为竞争信号量时需要使进程睡眠和再次唤醒，代价更高。

使用

```
count = 1;
DECLARE_MUTEX(mutex)
...
down(&mutex);
/* 临界区 */
up(&mutex);
```

进入临界区，用down对使用计数器减1。在计数器为0时，其他进程不能进入临界区。

在试图用down获取已经分配的信号量时，当前进程进入睡眠，并放置在与该信号量关联的等待队列上。同时，该进程被设置于TASK_UNINTERRUPTIBLE状态，在等待进入临界区的过程中无法接收信号。如果信号量没有分配，该进程可以立即获取信号量并进入到临界区，而不会进入睡眠。

除了down操作之外，还有其他两种操作用于获取信号量。

- down_interruptible工作方式与down相同，但如果无法获取信号量，则将进程置于TASK_INTERRUPTIBLE状态。因此，在进程睡眠时可以通过信号唤醒
- down_trylock试图获取信号量。如果失败，则进程不会进入睡眠等待信号量，而是继续正常执行。如果获取了信号量，则该函数返回false，否则返回true。

除了只能用于内核的互斥量之外，linux也提供了futex(快速用户空间互斥量)，由核心态和用户态组合而成。它为用户空间进程提供了互斥量功能。

### RCU机制

原理：该机制记录了指向共享数据结构的指针的所有使用者。在该结构将要改变时，则首先创建一个副本(或一个新的实例，填充适当的内容)，在副本中修改。在所有进行读访问的使用者结束对旧副本的读取之后，指针可以替换为指向新的，修改后副本的指针。

RCU对潜在使用者提出一些约束

1. 对共享资源的访问在大部分时间应该是只读的，写访问应该相对很少
2. 在RCU保护的代码范围内，内核不能进入睡眠状态
3. 受保护资源必须通过指针访问

**核心API**

假定指针ptr指向一个被RCU保护的数据结构。直接反引用指针是禁止的，首先必须调用rcu_dereference(ptr)，然后反引用返回结果。此外，反引用指针并使用其结果的代码，需要用rcu_read_lock和rcu_read_unlock调用保护起来

```
rcu_read_lock();

p = rcu_dereference(ptr);
if (p != NULL){
  awesome_function(p);
}

rcu_read_unlock();
```

如果必须修改ptr指向的对象，则需要使用rcu_asign_pointer：

```
struct super_duper *new_ptr = kmalloc(...);

new_ptr->meaning = xyz;
new_ptr->of = 42;
new_pt->life = 23;
rcu_assign_pointer(ptr,new_ptr);
```

在新值已经公布之后，所有的读访问完成之后，内核可以释放该内存，但它需要知道何时释放内存是安全的。RCU提供另外两个函数。

- synchronize_rcu()等待所有现存的读访问完成。在该函数返回之后，释放与原指针关联的内存是安全的

- call_rcu可用于注册一个函数，在所有针对共享资源的读访问完成之后调用。这要求将一个rcu_head实例嵌入到RCU保护的数据结构

  ```
  struct super_duper{
    strcut rcu_head head;
    int meaning, of, life;
  }
  ```

该回调函数可用通过参数访问对象的rcu_head成员，进而使用container_of机制访问对象本身。

**链表操作**

RCU不仅能保护一般指针，也能保护双链表。此外，由struct hlist_head和struct hlist_node组成的散列表也可以通过RCU保护。

- list_add_rcu将新的链表元素new添加到表头为head的链表头部，而list_add_tail_rcu将其添加到链表尾部
- list_replace_rcu将链表元素old替换为new
- list_del_rcu从链表删除链表元素entry

最终要的函数：list_for_each_rcu允许遍历链表的所有元素；list_for_each_rcu_safe对删除链表元素是安全的

这两个操作都必须通过一对rcu_read_lock()和rcu_read_unlock()包围。

### 内存和优化屏障

内核提供几个函数，可阻止处理器和编译器进行代码重排

- mb()，rmb()，wmb()将硬件内存屏障插入到代码流程。rmb()是读访问内存屏障。它保证在屏障之后发出的任何的读取操作执行之前，屏障之前发出的所有读取操作都已经完成。wmb()使用于写访问，语义与rmb()类似。mb()合并二者的语义
- barrier插入一个优化屏障。该指令告知编译器，保存在CPU寄存器中，在屏障之前有效的所有内存地址，在屏障之后都将失效。本质上，这意味着编译器在屏障之前发出的读写请求完成之前，不会处理屏障之后的任何读写请求。但CPU仍然可以重排时序
- smb_mb()，smp_rmb()，smp_wmb()相当于上述的硬件内存屏障，但只用于SMP系统。它们在单处理器系统上产生的是软件屏障
- read_barrier_depends()是一种特殊形式的读访问屏障，它会考虑操作之间的依赖性。如果屏障之后的读请求的数据，那么编译器和硬件都不能重排这些请求


优化屏障的一个特定应用是内核抢占机制。preempt_disable对抢占计数器加1因而停用了抢占，preempt_enable通过对抢占计数器减1而再次启用抢占。这两个命令之间的代码，可免受抢占的影响。

代码如下

```
preempt_disable();
function_which_must_not_be_preempted();
preempt_enable();

// 如果编译器决定将代码重新排序如下，那么就相当麻烦
function_which_must_not_be_preempted();
preempt_disable();
preempt_enable();

// 另一种可能的重排同样有问题
preempt_disable();
preempt_enable();
function_which_must_not_be_preempted();
```

以上这两种情况，不可抢占的部分都会变得可抢占。因此，preempt_disable在抢占计数器加1之后插入一个内存屏障

```
#define preempt_disable() \
do{ \
...
	inc_preempt_count(); \
	barrier(); \
}while(0)
```

这防止了编译器将inc_preempt_count()与后续语句交换位置。同样，preempt_enable必须在再次启用抢占之前插入一个优化屏障。

```
#define preempt_enable() \
do{ \
...
	barrier(); \
	preempt_check_resched(); \
}while(0)
```

这种措施可以防止上文中第二种错误的重排。

### 读者/写者锁

读者/写者自旋锁定义为rwlock_t数据类型。必须根据读写访问，以不同的方式获取锁。

- 进程对临界区进行读访问时，在进入和离开时需要分别执行read_lock和read_unlock。内核会允许任意数目的读进程并发访问临界区
- write_lock和write_unlock用于写访问。内核保证只有一个写进程能够处于临界区

_irq_irqsave变体也同样可用，运作方式如同普通的自旋锁。以 _bh结尾的变体也是可用的。

读/写信号量的用法类似。所用的数据结构是struct rw_semaphore，down_read和up_read用于获取对临界区的读访问。写访问借助down_write和up_write进行。_trylock变体对所有命令都可用。

### 大内核锁

可以锁定整个内核，确保没有处理器在核心态并运行。该锁称为大内核锁，BKL。

它的锁深度也会进行计数，在内核已经锁定时，仍然可以调用lock_kernel。对应的解锁操作(unlock_kernel)必须调用同样的次数，以解锁内核，使其他处理器能够进入。

### 互斥量

**经典互斥量**

数据结构

```
struct mutex{
  /* 1:未锁定 0:锁定 负值:锁定，可能有等待者 */
  atomic_t count;
  spinlock_t wait_lock;
  struct list_head wait_list;
};
```

如果互斥量未锁定，则count为1。锁定分为两种：1) 如果只有一个进程在使用互斥量，则count设置为0。2) 如果互斥量被锁定，而且有进程在等待互斥量解锁(在解锁时需要唤醒等待进程)，则count为负值。这种特殊处理有助于加快代码的执行速度。

有两种方法定义新的互斥量

1. 静态互斥量可以在编译时通过使用DEFINE_MUTEX产生
2. metux_init在运行动态初始化一个新的互斥量

mutex_lock和mutex_unlock分别用于锁定和解锁互斥量。此外内核也提供mutex_trylock，该函数尝试获取互斥量。如果互斥量已经锁定，则立即返回。最后，metux_trylock可用于检查给定的互斥量是否锁定

**实时互斥量**

它们需要在编译时通过配置选项CONFIG_RT_MUTEX显式启用。与普通互斥量相比，它们实现了优先级继承，该特性可用于解决优先级反转的影响。

**例子：** 进程A优先级高，进程C优先级低。假定进程C已经获取了一个互斥量，正在所保护的临界区中运行，且在短时间内不打算退出。但在进程C进入临界区之后，进程A也试图获取保护临界区的互斥量。由于进程C已经获取该互斥量，因而进程A必须等待。这导致高优先级的进程A等待低优先级的进程C。

如果有第3个进程B，优先级介于进程A和进程C之间，情况会更加糟糕。假定进程C仍然持有锁，进程A在等待。现在进程B开始运行。由于它的优先级高于进程C，因此可以抢占进程C。但它实际上也抢占了进程A。如果进程B继续运行，会让进程A等待时间更长。这称为无限制优先级反转。

如果高优先级进程阻塞在互斥量上，该互斥量当前由低优先级进程持有，那么进程C的优先级临时提高到进程A的优先级。如果进程B现在开始运行，只能得到与进程A竞争情况下的CPU时间，从而理顺优先级的问题。

实时互斥量的定义

```
struct rt_mutex{
  spinlock_t wait_lock;
  struct plist_head wait_list;
  struct task_struct *owner;
};
```

互斥量的所有者通过owner指定，wait_lock提供实际的保护。所有等待的进程都在wait_list中排队。与普通互斥量相比，决定性的改变是等待列表中的进程优先级排序。在等待列表改变时，内核可相应地校正锁持有者的优先级。由函数rt_mutex_setprio提供。

### 近似的per-CPU计数器

如果系统安装有大量CPU，计数器可能成为瓶颈：每次只有一个CPU可以修改其值，所有其他CPU都必须等待操作结束，才能再次访问计数器。如果计数器频繁访问，则会严重影响系统性能。

对某些技术器，没有必要时时了解其准确的数值。这种计数器的近似值和准确值，作用上没什么差别。可以利用这种情况，引入所谓per-CPU计数器，来加速SMP系统上计数器的操作。

基本思想：计数器的准确值存储在内存中某处，准确值所在内存位置之后是一个数组，每个数组项对应于系统中的一个CPU。

|   准确值    |
| :------: |
| per-CPU1 |
| per-CPU2 |
| per-CPU3 |
| per-CPU4 |

如果一个处理器想要修改计数器的值(加上或减去某个值n)，它不会直接修改计数器的值，因为这需要防止其他CPU访问计数器(费时操作)。相反，所需的修改将保存到与计数器相关的数组中特定于当前CPU数组项。

**例子：** 如果计数器的原值是15，现在计数器加3，那么数组中的对应数组项为+3。如果同一个CPU在其他时间需要从计数器中减去5，它不会对计数器直接操作，而是操作数组中特定于CPU的项，结果是13。任何处理器读取计数器值，都不会准确，可能仍然是15。如果只需要大致了解计数器的值，13也算得当是15的一个比较好的近似。

### 锁竞争与细粒度锁

锁需要满足下面两个目的

1. 必须防止对代码的并发访问，否则将导致失败
2. 对性能的影响必须尽可能小

多个数据结构，整个驱动程序或整个子系统由一个锁保护，那么在内核的某个部分需要获取锁的时候，该锁已经I系统其他部分获取的概率是很高的。这种情况下出现较多的锁竞争，该锁会成为内核的一个热点。

标识数据结构中各个独立的部分，使用多个锁来保护结构的成员，这种解决方案称为细粒度锁。可能会引发的问题

1. 获取多个锁会增加操作的开销，特别是在较小的SMP计算机上
2. 在通过多个锁保护一个数据结构时，很自然会出现一个操作需要同时访问两个受保护区域的情形，因而需要同时持有多个锁。这要求必须遵守某种锁定次序，必须按序获取和释放锁。否则，仍然会导致死锁。

## System V进程间通信

Linux使用System V引入的机制，来支持用户进程的进程间通信和同步。内核通过系统调用提供了各种例程，使用用户库能够实现所需的操作。

### System V机制

3种进程间通信(IPC)

1. 信号量
2. 消息队列
3. 共享内存

它们都使用了全系统范围的资源，可以由几个进程同时共享。

IPC对象必须在系统内唯一标识。为此，每种IPC结构在创建时分配了一个号码。如果独立的应用程序需要彼此通信，则通常需要将该魔数永久地编译到程序中。

在访问IPC对象时，系统采用了基于文件访问权限的一个权限系统。每个IPC对象都有一个用户ID和一个组ID。依赖于产生IPC对象的程序在何种UID/GID之下运行。读写权限在初始化时分配。类似于普通文件，这些控制了3中不同用户类别的访问：所有者、组、其他。

### 信号量

**使用System V信号量**

```
#define SEMKEY 1234L /* 标识符 */
#define PERMS 0666 /* 访问权限：rwrwrw */

struct sembuf op_down[1] = {0, -1, 0};
struct sembuf op_up[1] = {0, 1, 0};

int semid = -1; /* 信号量 */
int res; /* 信号量操作的结果 */

void int_sem(){
  /* 测试信号量是否已经存在 */
  semid = semget(SEMKEY, 0, IPC_CREAT | PERMS);
  if(semid < 0){
    printf("create the semaphore!\n");
    
    semid = semget(SEMKEY, 1, IPC_CREAT | PERMS);
    if(semid < 0){
      printf("couldn't create semaphore!\n");
      exit(-1);
    }
    
    /* 初始化为1 */
    res = semctl(semid, 0, SETVL, 1);
  }
}

void down(){
  /* 执行down操作 */
  res = semop(semid, &op_down[0], 1);
}

void up(){
  /* 执行up操作 */
  res = semop(semid, &op_up[0], 1);
}

int main(){
  init_sem();
  /*  正常的程序代码 */
  printf("before critical code\n");
  down();
  /* 临界区代码 */
  pringf("in critical code\n");
  sleep(10);
  up();
  /* 其余代码 */
  return 0;
}
```

1. 首先在main中用一个持久定义的魔数(1234)创建一个新的信号量，以便在系统内建立标识。
2. 可能有几个副本同时运行，因此测试对应的信号量是否已经存在。如果没有，则创建信号量。
3. up和down操作用同名的函数实现。操作使用semop系统调用进行，照例使用semid变量标识信号量。
4. 数组每个sembuf项由3个成员组成
   - 第一个：选择信号量集合中需要操作的信号量
   - 第二个：0表示一直等待，直到信号量的值达到0。正数表示将该值加到信号量。负数用于请求资源。如果其绝对值小于信号量的值，则从当前信号量减去其值，不会在信号量上睡眠；否则进程将被阻塞，直至信号量值恢复到允许操作进行的程度
   - 第三个：标志，用于精细控制操作


该程序首先创建信号量，然后进入临界区代码，并等待10秒。在进入临界区之前，执行一个down操作，将信号量的值减1，得到0。如果有另一个进程在第一个进程等待期间启动，则不允许进入临界区代码。

试图进入临界区代码将触发down操作，该操作将从信号量值减去1.由于当前值为0，操作会失败。进程将在信号量上进入睡眠，直至第一个进程通过up操作释放资源(信号量值恢复到1)，才会唤醒第二个进程。记下来它可以将信号量值减1并进入临界区代码。

**数据结构**

内核使用了几个数据结构来描述所有注册信号量的当前状态，并建立一种网状结构。它们不仅负责管理信号量及其特征(值、读写权限等)，还负责通过等待列表将信号量与等待进程关联。

命名空间

```
struct ipc_namespace{
  struct ipc_ids *ids[3];
  /* 资源限制 */
...
} 
```

内核会限制共享内存页的最大数目，共享内存段的最大长度、消息队列的最大数目。所有的限制都以命名空间为基础实施。

ids每个数组元素对应于一种IPC机制：共享内存、信号量、消息队列。每个数组指向一个struct ipc_ids实例，该结构用于跟踪各类别现存的IPC对象。

ipc_ids定义

```
struct ipc_ids{
  int in_use;
  unsigned short seq;
  unsigned short seq_max;
  struct rw_semaphore rw_mutex;
  struct idr ipcs_idr;
}
```

- in_use保存当前使用中IPC对象状态的一般信息
- seq和seq_max用于连续产生用户空间IPC ID。内核通过ID来表示IPC对象，ID按自愿类型管理，即一个ID用于消息队列，一个用于信号量，一个用于共享内存对象。每次创建新的IPC对象时，序号加1(自动回绕，到最大值自动变0)
- rw_mutex是一个内核信号量。它用于是吸纳信号量操作，避免用户空间的竞态条件。有效地保护了包含信号量值的数据结构

每个IPC对象都由kern_ipc_perm的一个实例表示。

kern_ipc_perm信息

```
struct kern_ipc_perm{
  int id;
  key_t key;
  uid_t uid;
  gid_t gid;
  uid_t cuid;
  gid_t cgid;
  mode_t mode;
  unsigned long seq;
}
```

该结构不仅可用于信号量，还可以用于其他的IPC机制

- key保存了用户程序用来表示信号量的魔数，id是内核内部的ID
- uid和gid分别指定了所有者的用户ID和组ID。cuid和cgid保存了产生信号量的进程的用户ID和组ID
- seq是一个序号，在分配IPC对象时使用
- mode保存位掩码，指定所有者，组，其他用户的访问权限

上述数据结构不足以保存信号量的所有信息。各进程的task_struct实例中有一个与IPC相关的成员

```
struct task_struct{
  ...
  #ifdef CONFIG_SYSVIPC
  /* ipc相关 */
  	struct sysv_sem sysvsem;
 #endif
 ...
};

struct sysv_sem{
  struct sem_undo_list *undo_list;
}
```

唯一的成员undo_list用于撤销信号量：如果进程在修改信号量之后崩溃，保存在该列表中的信息可用于将信号量的状态恢复到修改之前，可以保持一致状态，防止死锁。

sem_queue，用于将信号量与睡眠进程关联起来，该进程想要执行信号量操作，但目前不允许执行。

sem_queue数据结构

```
struct sem_queue{
  struct sem_queue *	next;	/* 队列中下一项 */
  struct sem_queue **	prev;	/* 队列中前一项 */
  struct task_struct *	sleeper;	/* 睡眠的进程 */
  struct sem_undo *		undo;	/* 用于撤销的结构 */
  int					pid;	/* 请求信号量的进程ID */
  int					status;	/* 操作的完成状态 */
  struct sem_array *	sma;	/* 操作的信号量数组 */
  int					id;		/* 内部信号量ID */
  struct sembuf *		sops;	/* 待决操作数组 */
  int 					nsops;	/* 操作数目 */
  int					alter;	/* 操作是否改变了数组 */
}
```

对每个信号量，都有一个队列管理与信号量相关的所有睡眠进程。该队列由next和prev是实现。

- sleeper是一个指针，指向等待执行信号量操作进程的task_struct实例
- pid指定了等待进程的PID
- id保存了内核内部的信号量ID
- sops是一个指针，指向保存待决信号量操作的数组。操作数目在nsops中定义
- alter表明操作是否修改信号量的值

sma保存一个指针，指向用于管理信号量状态的数据结构实例

```
struct sem_array{
  struct kern_ipc_perm	sem_perm;	/* 权限，参见ipc.h */
  time_t				sem_otime;	/* 最后一次信号量操作的时间 */
  time_t				sem_ctime;	/* 最后一次修改的时间 */
  struct sem			*sem_base;	/* 指向数组中第一个信号量的指针 */
  struct sem_queue		*sem_pending;	/* 需要处理的待决操作 */
  struct sem_queue		**sem_pending_last;	/* 上一个待决操作 */
  struct sem_undo		*undo;		/* 该数组上的撤销请求 */
  unsigned long			sem_nsems;	/* 数组中信号量的数目 */
}
```

系统中的每个信号量集合，都对应该数据结构的一个实例。用于管理集合中所有信号量

- 信号量访问权限保存在kern_ipc_perm类型的sem_perm成员中。该成员必须位于结构的起始处

- sem_nsems指定一个用户信号量集合中信号量的数目

- sem_base是一个数组，每个数组项描述了集合中的一个信号量。其中保存了当前信号量值和上一个访问它的进程PID

  ```
  struct sem{
    int semval;
    int sempid;
  }
  ```

- sem_otime指定了上一次访问信号量的时间，单位是jiffies。sem_ctime指定了上次修改信号量值的时间

- sem_pending指向待决信号量操作的链表。sem_pending_last用于快速访问该链表的最后一个元素，而sem_pending指向链表的起始

信号量的当前状态需要通过与另外两个结构的联系获取

- 待决操作通过sem_queue实例的链表管理。等待操作执行的睡眠进程，也可以通过该链表确定
- struct sem实例的数组用于保存集合由各个信号量的值

![img](https://img-blog.csdn.net/20141125221501765?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGlleWVfbGVhdmVz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

每个sem_queue成员包含了一个指针，执行sem_ops实例的数组。

```
struct sembuf{
  unsigned short	sem_num;	/* 信号量在数组中的索引 */
  short				sem_op;		/* 信号量操作 */
  short				sem_flg;	/* 操作标志 */
}
```

这个就是用于描述对信号量操作的数据结构。不仅保存了信号量在信号量集合中的索引，还有所要进行的操作(sem_op)和一些操作标志(sem_flg)。

**实现系统调用**

所有对信号量的操作都使用一个名为ipc的系统调用执行。该调用不仅用于信号量，也用于操作消息队列和共享内存。

用于信号量的函数

- SEMCTL执行信号量的操作，并由sys_semctl实现
- SEMGET读取信号量ID，相关的实现由sys_semget提供
- SEMOP和SEMTIMEDOP负责增加减少信号量值，后者可以指定超时时间限制

![img](http://images2015.cnblogs.com/blog/1004410/201608/1004410-20160807160125200-1760151616.png)

**权限检查**

IPC对象的保护机制，与普通的基于文件的对象相同。定义如下

```c
struct ipcperms(struct kern_ipc_perm *ipcp, short flag){
  /* 大多数情况下，flag都是0或<linux/sata.h>中定义的S_...UGO */
  int requested_mode, granted_mode, err;
  ...
  requested_mode = (flag >> 6) | (flag >> 3) | flag;
  granted_mode = ipcp->mode;
  
  if(current->euid == ipcp->cuid || current->euid == ipcp->uid)
  	granted_mode >>= 6;
  	
  else if(in_group_p(ipcp->cuid || current->euid == ipcp->uid))
  	granted_mode >>= 3;
  
  /* 是否有某些比特位在requested_mode中置位，但在granted_mode中没有置位*/
  if(requested_mode & ~granted_mode & 0007) && !capable(CAP_IPC_OWNER)
  	return -1;
  return security_ipc_permission(ipcp,flag);
}
```

request_mode包含了所请求的权限位。granted_mode初始值包含IPC对象的权限位。

如果request_mode和granted_mode的最后3个比特位不符合授权规则，则拒绝授权。securit_ipc_permission将挂钩到其他安全性框架中。

### 消息队列

进程间通信另一个方法是交换消息，使用消息队列机制完成。

消息队列的原理

![img](https://img2018.cnblogs.com/blog/1459272/201812/1459272-20181212223152736-951670590.png)

产生消息并将其写入到队列的进程通常称为发送者，而一个或多个其他进程则从队列获取信息。各个消息包含消息正文和一个(正)数，以便在消息队列内实现集中类型的消息。接受者可以根据该数字检索信息。在消息已经读取后，内核将其从队列删除。即使几个进程在同一信道上监听，每个消息仍然只能由一个进程读取。

同一编号的消息按先进先出次序处理。消息队列也是使用此前的数据结构。起始点是当前命名空间的适当的ipc_ids实例。同样，内部的ID号形式上关联到kern_ipc_perm实例。

通过类型获得不同的数据结构(struct msg_queue):

```c
struct msg_queue{
  struct kern_ipc_perm q_perm;	
  time_t q_stime;	/* 上一次调用msgsnd发送消息的时间 */
  time_t q_rtime;	/* 上一次调用msgrcv接收消息的时间 */
  time_t q_ctime;	/* 上一次修改的时间 */
  unsigned long q_cbytes;	/* 队列上当前字节数目 */
  unsigned long q_qnum;		/* 队列中的消息数目 */
  unsigned long q_qbytes；  /* 队列上最大字节数目 */
  pid_t q_lspid; 	/* 上一次调用msgsnd的pid */
  pid_t q_lrpid; 	/* 上一次接收消息的pid */
  struct list_head q_messages;
  struct list_head q_receivers;
  struct list_head q_senders;
}
```

该结构包含状态信息以及队列访问权限

- q_stime、q_rtime和q_ctime分别制定上一次发送、接收和修改的时间
- q_cbytes制定队列中当前用于消息的字节数目
- q_qbytes制定队列中可能用于消息的字节的最大数目
- q_num制定队列中消息的数目
- q_lspid是上一个发送进程PID，q_lrpid是上一个接收进程的PID

3个标准的内核链表用于管理睡眠的发送者，睡眠的接收者和消息本身。各链表的数据结构

```
struct msg_msg{
  struct list_head m_list;
  long m_type;
  int m_ts;	/* 消息正文长度 */
  struct msg_msgseg* next;
  /* 接下来是实际的消息 */
}
```

m_list用于连接各个消息的元素

- m_type制定消息类型，用于支持消息队列中不同的消息类型
- m_ts制定消息正文长度，按字节计算
- 如果保存超过一个内存页的长消息，则需要next

每个消息都分配一个内存页，msg_msg实例保存在该页起始处，剩余空间可用于存储消息正文

![img](https://img2018.cnblogs.com/blog/1459272/201812/1459272-20181212223340616-426428979.png)

从内存页的长度，减去msg_msg结构的长度，即可得到msg_msg页中可用于消息正文的最大字节数目。

更长的消息必须借助于next指针，分页在几个页中，该指针指向页开始处的msg_msgseq实例

```c
struct msg_msgseg{
	struct msg_msgseg* next;
	/* 接下来是消息的下一部分 */
}
```

在通过消息队列通信时，发送进程和接收进程都可以进入睡眠：如果消息队列已经达到最大容量，则发送者在试图写入消息时会进入睡眠；如果队列中没有消息，那么接受者在试图获取消息时会进入睡眠。

睡眠的发送者放置在msg_queue的q_senders链表中，链表元素使用下列数据结构

```c
struct msg_sender{
  struct list_head list;
  struct task_struct* tsk;
}
```

list是链表元素，tsk是指向对应进程的task_struct指针。

q_receivers链表用于保存接收进程的数据结构要稍微长一点

```c
struct msg_receiver{
	struct list_head r_list;
	struct task_struct *r_tsk;
	
	int r_mode;
	long r_msgtype;
	long r_maxsize;
}
```

其中不仅保存指向对应进程的task_struct指针，还包括对预期消息的描述，以及指向msg_msg实例的一个指针。在有消息可用的情况下，该指针指定了复制数据的目标地址。

![img](https://img2018.cnblogs.com/blog/1459272/201812/1459272-20181212223520092-154180180.png)

### 共享内存

从用户和内核角度看，它的实现使用与信号量、消息队列机制类似的结构。

- 应用程序请求IPC对象，可以通过魔数和当前命名空间的内核内部ID访问
- 对内存的访问，可能受到权限系统的限制
- 可以使用系统调用分配与IPC对象关联的内存，具备适当授权的所有进程，都可以访问该内存

![img](https://img2018.cnblogs.com/blog/1459272/201812/1459272-20181212223632129-1941423205.png)

同样，在smd_ids全局变量的entries数组中保存kern_ipc_perm和shmid_kernel的组合，以便管理IPC对象的访问权限。对每个共享内存对象都创建一个伪文件，通过shm_file连接到shmid_kernel实例。

内核使用shm_file->f_mapping指针访问地址空间对象(struct address_space)，用于创建匿名映射，还需要设置涉及各个进程的页表，使得各个进程都能够访问与该IPC对象相关的内存区域。

## 其他IPC机制

### 信号

信号是一种原始的通信机制。提供喧嚣少，kill命名根据PID向进程发送信号。信号通过-s sig指定，是一个正整数，最大长度取决于处理器类型。

进程必须设置处理程序例程处理信号。这些例程在信号发送到进程时调用。如果没有显式设置除了程序例程，内核使用默认的处理程序实现。

信号引入特性

- 进程可以决定阻塞特定的信号(信号屏蔽)
- SIGKILL信号无法阻塞，也不能通过特定于进程的处理程序处理
- init进程属于特例。内核会忽略发送给该进程的SIGKILL信号。因为该进程对整个系统尤其重要，不能强制结束该进程

**实现信号的处理程序**

sigaction系统调用用于设置新的处理程序

```c
#include <signal.h>
#include <stdio.h>

/* 处理程序函数 */
void handler(int sig){
  printf("receive signal: %u\n",sig);
};

int main(void){
  struct sigaction sa;
  int count;
  
  /* 初始化信号处理程序结构 */
  sa.sa_handler = handler;
  sigemptyset(&sa.sa_mask);
  sa.sa_flags = 0;
  
  /* 给SIGTERM信号分配一个新的处理程序函数 */
  sigaction(SIGTERM, &sa, NULL);
  sigprocmask(%sa.sa_mask);
  /* 阻塞，一直等到信号到达 */
  while(1){
    sigsuspend(&sa.sa_mask);
    printf("loop\n");
  }
  
  return 0;
}
```

如果没有为某个信号分配用户定义的处理程序函数，内核会自动设置预定义函数，提供合理的标准操作来处理相应的情况。

sigaction类型中用于描述处理程序的字段，其定义是平台相关的，但在所有体系结构上几乎都相同

```c
struct sigaction{
  __sighandler_t sa_handler;
  unsigned long sa_flags;
  ...
  sigset_t sa_mark; /* mask last for extensibility */
}
```

- sa_handler是一个指针，指向内核在信号到达时调用的处理程序函数
- sa_mask包含一个位掩码，每个比特位对应于系统中一个信号。用于在处理程序例程执行期间阻塞其他信号
- sa_flags包含额外的标志，用于指定信号处理方式的一些约束

信号处理函数原型

```c
typedef void __signalfn_t (int);
typedef __signalfn_t __user *__sighandler_t;
```

其参数是信号的编号，可以使用同一个处理程序函数处理不同的信号。

程序的最后一个步骤是使用sigsuspend系统调用等待一个信号。此时进程被阻塞，处于睡眠状态，直至有信号到达唤醒进程，然后又立即进入睡眠状态。

**实现信号处理**

所有信号相关的数据都是借助于链式数据结构管理，入口是task_struct结构

```c
struct task_struct{
  ...
  /* 信号处理程序 */
  struct signal_struct *signal;
  struct sighand_struct *sighand;
  
  sigset_t blocked;
  struct sigpending pending;
  
  unsigned long sas_ss_sp;
  size_t sas_ss_size;
  ...
}
```

下列结构的sighand成员，用于管理设置的信号处理程序的信息

```c
struct sighand_struct{
  atomic_t count;
  struct k_sigaction action[_NSIG];
};
```

- count保存共享该结构实例的进程数目，clone操作可以指定父子进程共享一个信号处理
- 设置的信号处理程序保存在action数组，共有_NSIG个。每个数组项包含一个k_sigaction结构实例，指定内核看到的信号属性

```c
struct k_sigaction{
  struct sigaction sa;
};
```

如果没有为信号设置用户定义的处理程序例程，则从4个标准操作择一执行

- 忽略：什么都不做
- 结束：结束进程或进程组
- 停止：将进程置于TASK_STOPPED状态
- 内存转储：创建地址空间的内存转储，并写入内存转储文件供进一步处理

**实现信号处理**

与信号相关的一些系统调用

|    系统调用     |        功能        |
| :---------: | :--------------: |
|    kill     | 向进程组的所有进程发送一个信号  |
|    tkill    |   向单个进程发送一个信号    |
| sigpending  |    检查是否有待决信号     |
| sigprocmask |    操作阻塞信号的位掩码    |
| sigsuspend  | 进入睡眠，直至接收到某个特定信号 |

1. 发送信号

   kill和tkill分别向进程组或单个进程发送信号。两个函数基本上相同，以sys_tkill为例，其代码流程图如图8所示。

   ![img](https://img2018.cnblogs.com/blog/1459272/201812/1459272-20181212224055310-2010294393.png)

2. 处理信号队列

   系统调用不会触发信号队列的处理，在每次由核心态切换到用户态时，内核都会发起信号队列处理。执行的最终效果就是调用do_signal函数

   - get_signal_to_deliver收集与需要传送的下一个信号有关的所有信息。它也特定于进程的待决信号链表中删除该信号
   - handle_signal操作进程在用户状态下的栈，使得从核心态切换到用户状态之后运行信号处理程序，而不是正常的程序代码。栈还会被修改，使得在处理程序函数结束时调用sigreturn系统调用。

![img](https://img2018.cnblogs.com/blog/1459272/201812/1459272-20181212224131597-1298006889.png)

### 管道和套接字

**管道**

将进程的输出用作另一个进程的输入，管道负责数据的传输。在通过shell产生管道时，总有一个读进程和一个写进程。应用程序必须调用pipe系统调用产生管道。该调用返回两个文件描述符，分别用于管道的两端，即分别用于管道的读和写。由于两个描述符存在同一个进程中，进程最初只能向自身发送消息。

**套接字**

套接字对象在内核中初始化返回一个文件描述符，因此可以向普通文件一样处理。但套接字可以双向使用，还可以用于通过网络连接的远程系统通信。







