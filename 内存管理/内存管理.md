# 内存管理

内存管理是内核最复杂同时也最重要的一部分，其特点在于非常需要处理器和内核之间的协作。

## 概述

内存管理的实现包括

- 内存中的物理内存页管理
- 分配大块内存的伙伴系统
- 分配较小块内存的slab、slub和slob分配器
- 分配非连续内存块的vmalloc机制
- 进程的地址空间

在IA-32系统上，地址空间在用户进程和内核之间划分的典型比例是3:1。给出4GiB虚拟地址空间，3GiB将用于用户空间而1GiB用于内核。

*注意：在启用PAE( page address extension )模式的情况，可以管理64GiB内存，但并非所有64GiB都可以同时寻址，而是每次只能寻址一个4GiB的内存段。*

两种类型计算机，分别以不同方法管理物理内存

1. UMA计算机(一致内存访问)：将可用内存以连续方式组织起来。SMP系统中每个处理器访问各个内存区都是同样快
2. NUMA计算机(非一致内存访问)：总是多个处理器计算机。系统的各个CPU都有本地内存访问，可支持特别快的访问。处理器间通过总线连接起来，以支持对其他CPU本地访问，比访问自身CPU本地内存慢。

TODO img

## (N)UMA模型中的内存组织

### 概述

内存划分为结点，每个结点关联到系统中的一个处理器，在内核中表示为pg_data_t的实例。

各个结点又划分为内存域，是内存的进一步细分。

![img](http://hi.csdn.net/attachment/201101/26/5118861_12960506363L93.jpg)

内核引入常亮来枚举系统中所有内存域

```c
enum zone_type{
  #ifdef CONFIG_ZONE_DMA
  	ZONE_DMA,
  #endif
  #ifdef CONFIG_ZONE_DMA32
  	ZONE_DMA32,
  #endif
  	ZONE_NORMAL,
  #ifdef CONFIG_HIGHMEM
  	ZONE_HIGHMEM,
  #endif
  	ZONE_MOVABLE,
  	MAX_NR_ZONES
};
```

- ZONE_DMA标记适合DMA的内存域，该区域的长度依赖于处理器类型。
- ZONE_DMA32标记使用32位地址字可寻址，适合DMA的内存域。
- ZONE_NORMAL标记可直接映射到内核段的普通内存域。这是在所有体系结构上保证都会存在唯一内存域，但无法保证该地址范围对应了实际的物理内存。
- ZONE_HIGHMEM标记超出内核段的物理内存
- ZONE_MOVABLE定义伪内存域，在防止物理内存碎片的机制中需要使用该内存域。
- MAX_NR_ZONES充当结束标记，在内核想要迭代系统中的所有内存域时，会用到该常亮。

各个内存域都关联一个数组，用来组织属于该内存域的物理内存页(页帧)。对每个页帧，都分配一个struct page实例以及所需的管理数据。

各个内存结点保存在一个单链表中，供内核遍历。

### 数据结构

**结点管理**

pg_data_t是用于标识结点的基本元素

```c
typedef struct pglist_data {
        struct zone node_zones[MAX_NR_ZONES];
        struct zonelist node_zonelists[MAX_ZONELISTS];
        int nr_zones;
        struct page *node_mem_map;
        struct bootmem_data *bdata;
        unsigned long node_start_pfn;
        /* 物理内存页总数 */
        unsigned long node_present_pages; 
        /* 物理内存页的总长度，包含洞在内 */
        unsigned long node_spanned_pages; 
        int node_id;
        struct pglist_data *pgdat_next;
        wait_queue_head_t kswapd_wait;
        struct task_struct *kswapd;
        int kswapd_max_order;
} pg_data_t;
```

- node_zones是一个数组，包含结点中各内存域的数据结构
- node_zonelists指定备用结点及其内存域的列表，以便在当前结点没有可用空间时，在备用结点分配内存
- 结点中不同内存域的数目保存在nr_zones
- node_mem_map是指向page实例数组的指针，用于描述结点的所有物理内存页。它包含结点中所有内存域的页
- 在系统启动期间，内存管理子系统初始化之前，内核也需要使用内存。为解决这个问题，内核使用自举内存分配器。bdata指向自举内存分配器数据结构的实例
- node_start_pfn是该NUMA结点第一个页帧的逻辑编号。系统中所有结点的页帧是依次编号的，每个页帧的号码都是全局唯一的
- node_id是全局结点ID。系统中的NUMA结点都从0开始编号
- pgdat_next连接到下一个内存结点，系统中所有结点都通过单链表连接起来，其末尾通过空指针标记
- kswapd_wait是交换守护进程的等待队列，在将页帧换出结点时会用到


结点及其包含的内存域之间的关联，以及备用列表，这些是通过结点数据结构起始处的几个数组建立的。

结点的内存域保存在node_zones[MAX_NR_ZONES]。该数组总是有3个项，即使结点没那么多内存域，也用0填充。

**结点状态管理**

如果系统结点多于一个，内核会维护一个位图，用以提供各个结点的状态信息。

```c
enum node_states{
  N_POSSIBLE,	/* 结点在某个时间可能变为联机 */
  N_ONLINE,		/* 结点是联机的 */
  N_NORMAL_MEMORY,	/* 结点有普通内存域 */
#ifdef CONFIG_HIGHMEM	
  N_HIGH_MEMORY,	/* 结点有普通或高端内存域 */
#else
  N_HIGH_MEMORY = N_NORMAL_MEMROY,	
#endif
  N_CPU,	/* 结点有一个或多个CPU */
  NR_NODE_STATES
};
```

状态N_POSSIBLE、N_ONLINE和N_CPU用于CPU和内存热插拔。

内存管理有必要的标志是N_HIGH_MEMORY和N_NORMAL_MEMROY：如果结点有普通或高端内存则使用N_HIGH_MEMORY，仅当结点没有高端内存才设置N_NORMAL_MEMROY。

两个辅助函数用来设置或清除位域或特定结点中的一个比特位

```c
void node_set_state(int node, enum node_states state)
void node_clear_state(int node, enum node_states state)
```

**内存域**

内核使用zone结构描述内存域

```c
struct zone{
  /* 通常由页分配器访问的字段 */
  unsigned long pages_min, page_low, pages_high;
  unsigned long lowmem_reserve[MAX_NR_ZONE];
  struct per_cpu_pageset pageset[NR_CPUS];
  
  /* 不同长度的空闲区域 */
  spinlock_t lock;
  struct free_area free_area[MAX_OREDR];
  ZONE_PADDING[_padl_]
  
  /* 通常由页面收回扫描程序访问的字段 */
  spinlock_t lru_lock;
  struct list_head active_list;
  struct list_head inactive_list;
  unsigned long nr_scan_active;
  unsigned long nr_scan_inactive;
  unsigned long pages_scanned;
  unsigned long flags;
  
  /* 内存域统计量 */
  atomic_long_t vm_stat[NR_VM_ZONE_STAT_ITEMS];
  
  int prev_priority;
  ZONE_PADDING[_pad2_]
  /* 很少使用或大多数情况下只读字段 */
    
  wait_queue_head_t *wait_table;
  unsigned long wait_table_hash_nr_entries;
  unsigned long wait_table_bits;
  
  /* 支持不连续内存模型的字段 */
  struct pglist_data *zone_pgdat;
  unsigned long zone_start_pfn;
  
  unsigned long spanned_pages;	/* 总长度，包含空洞 */
  unsigned long present_pages;	/* 内存数量(除去空间) */
  
  /* 很少使用的字段 */
  char *name;
}__cacheline_maxaligned_in_smp;
```

由ZONE_PADDING分隔几个部分，这是因为对zone结构访问非常频繁。在多处理器系统上，通常会有不同的CPU试图同时访问结构成员。因此使用锁防止它们彼此干扰，避免错误和不一致。获取该结构的两个自旋锁zone->lock和zone->lru_lock。

- pages_min、pages_high、pages_low是页换出使用的"水印"。如果内存不足，内核可以将页写到硬盘。这3个成员会影响交换守护进程的行为。

  - 如果空闲页多于pages_high，则内存域的状态是理想的
  - 如果空闲页的数目低于pages_low，则内核开始将页换出到硬盘
  - 如果空闲页的数目低于pages_min，那么页回收工作的压力比较大，因为内存域中急需空闲页

- lowmem_reserve数组分别为各种内存域指定若干页，用于一些无论如何都不能失败的关键性内存分配。

- pageset是一个数组，用于实现每个CPU的热/冷页帧列表。有些页帧很可能在高速缓存中，因此可以快速访问，故称为热的；未缓存的页帧与此相对，故称为冷的。

- free_area是同名数据结构的数组，用于实现伙伴系统。每个数组元素都表示某种固定长度的一些连续内存区。对于包含在每个区域的空闲内存页的管理，free_area是一个起点。

- 第二部分结构成员，用来根据活动情况对内存域中使用的页进行编目。在需要换出页时，如果可能，频繁使用的页应该保持不动，而多余的不活动页则可以换出而没有什么损害

  - active_list是活动页的集合，而inactive_list则不活动页的集合

  - nr_scan_active和nr_scan_inactive指定在回收内存时需要扫描的活动和不活动的数目

  - pages_scanned指定上次换出一页以来，有多少页未能成功扫描

  - flags描述内存域的当前状态

    ```
    typedef enum{
      ZONE_ALL_UNRECLAIMABLE,	/* 所有的页都已经"钉"住 */
      ZONE_RECLAIM_LOCKED,		/* 防止并发回收 */
      ZONE_OOM_LOCKED,			/* 内存域即可被回收 */
    } zone_flags_t;
    ```

  - vm_stat维护大量有关该内存域的统计信息。例如：可以将item参数设置为NR_ACTIVE或NR_INACTIVE，来查询存储在active_list和inactive_list中的活动和不活动页的数目。设置NR_FREE_PAGES则可以获得内存域中空闲页的数目。

  - prev_priority存储上一次扫描操作扫描该内存域的优先级，扫描操作是由try_to_free_pages进行，直到释放足够的页帧。

  - wait_table、wait_table_bits和wait_table_hash_nr_entries实现一个等待队列，可用于等待某一项变为可用进程。：进程排成一个队列，等待某些条件。在条件变为真时，内核通知进程恢复工作。

  - 内存域和父结点之间的关联由zone_pgdat建立，zone_pgdat指向相应的pg_list_data实例

  - zone_start_pfn是内存域第一个页帧的索引

  - 剩余三个字段很少使用，因此置于数据结构的末尾

    - name保存内存域的惯用名称:Normal、DMA和HighMem
    - spanned_pages指向内存域中页的总数
    - present_pages给出实际上可用的页数目

**内存域水印的计算**

内存首先确定需要为关键性分配保留的内存空间最小值。该值随可用内存大小而非线性增长，并保存在全局变量min_free_kbytes中。

img TODO

数据结构中水印值的填充由init_per_zone_pages_min处理，该函数由内核启动期间调用，无需显式调用。

代码流程：

1. setup_per_zone_pages_min设置struct zone的page_min、pages_low和pages_high成员。在计算出高端内存域之外页面的总数之后(保存在lowmem_pages)，内核迭代系统中的所有内存域并执行计算。
2. lowmem_reserve的计算由setup_per_zone_lowmem_reserve完成。内核迭代系统的所有结点，对每个结点的各个内存域分别计算预留内存最小值。具体的算法是将内存域中页帧的总数除以sys_ctl_lowmem_reserve_ratio[zone]。除数默认设置对低端内存域是256，对高端内存域是32。

主内存大小与可用关键性分配内存空间最小值关系

|  主内存大小   |  保留内存大小  |
| :------: | :------: |
|  16MiB   |  512KiB  |
|  32MiB   |  724KiB  |
|  64MiB   | 1024KiB  |
|  128MiB  | 1448KiB  |
|  256MiB  | 2048KiB  |
|  512MiB  | 2896KiB  |
| 1024MiB  | 4096KiB  |
| 2048MiB  | 5792KiB  |
| 4096MiB  | 8192KiB  |
| 8192MiB  | 11584KiB |
| 16384MiB | 16384KiB |

**冷热页**

stuct zone的pageset成员用于实现冷热分配器。

内核说页是热的，意味着页已经加载到CPU高速缓存，与在内存中的页相比，其数据能够更快访问。

pageset是一个数组，其容量与系统能够容纳的CPU数目的最大值相同。

```c
struct zone{
  ...
  struct per_cpu_pageset pageset[NR_CPUS];
  ...
}
```

数组元素类型per_cpu_pageset定义：

```c
struct per_cpu_pageset{
  struct per_cpu_pages pcp[2]; /* 索引0对应热页，1对应冷页 */
}__cacheline_aligned_in_smp;
```

数组构成管理热页和冷页，有用的数据保存在per_cpu_pages

```c
struct per_cpu_pages{
  int count;		/* 列表中页数 */
  int high;			/* 页数上限水印，在需要的情况下清空列表 */
  int batch;		/* 添加/删除多页块的时候，块的大小 */
  struct list_head list	/*页的链表 */
}
```

imgTODO

 **页帧**

页帧代表系统内存的最小单位，对内存中的每个页都会创建struct page的实例。

内的广泛使用，增加保持结构长度的难度：内存管理的许多部分都使用页，用于各种不同的用途。内核一个部分可能完全依赖于struct page提供的特定信息，而该信息对内核的另一部分可能完全没用，该部分依赖于struct page提供的其他信息，而这部分信息对内核的其他部分也可能是完全无用的。

使用C语言的联合适合该问题，可以确保只有内核会使用该页，而不会有其他地方使用。

```c
struct page{
  ...
  union{
    atomic_t _mapcount;		/* 内存管理子系统中映射的页表项计数，用于表示页是否已经映射，还用于限制
    						   逆向映射搜索 */
    unsigned int inuse;		/* 用于SLUB分配器，对象的数目 */
  };
  ...
}
```

**page的定义**

该结构定义如下

```c
struct page{
  unsigned long flags;		/* 原子标志，有些情况下会异步更新 */
  atomic_t _count;			/* 使用计数，见下文 */
  union{
    atomic_t _mapcount;		/* 内存管理子系统中映射的页表项计数，用于表示页是否已经映射，还用于限制
    						   逆向映射搜索 */
    unsigned int inuse;		/* 用于SLUB分配器，对象的数目 */
  };
  union{
    struct {
      unsigned long private;	/* 由映射私有，不透明数据：
      							 * 如果设置PagePrivate,通常用于buffer_heads
                                 * 如果设置PageSwapCache，则用于swp_entry_t;
                                 * 如果设置PG_buddy，则用于表示伙伴系统中的阶
                                 */
      struct address_space *mapping;	/* 如果最低位为0，则指向inode
      									 * address_space，或为NULL。
                                         * 如果页映射为匿名内存，最低位置为位，
                                         * 而且该指针指向anon_vma对象；
                                         * 参见下文PAGE_MAPPING_ANON
                                         */
    };
    struct kmem_cache *slab;	/* 用于SLUB分配器：指向slab的指针 */
    struct page *first_page;	/* 用于复合页的尾页，指向首页 */
  };
  union{
    pgoff_t index;				/* 用于SLUB分配器：指向slab指针 */
    void *freelist;				/* SLUB:freelist req. slab lock */
  };
  struct list_head lru;			/* 换出页列表，例如由zone->lru_lock保护的active_list! */
  #if defined(WAIT_PAGE_VIRTUAL)
  	void *virtual;				/* 内核虚拟地址*/
  #endif	
}
```

**体系结构无关的页标志**

页的不同属性通过一系列标志描述，存储为struct page的flags成员中的各个比特位。

重要的标志

- PG_locked指定页是否锁定。如果该比特位置位，内核其他部分不允许访问该页。这防止内存管理出现竞态条件，例如：从硬盘读取数据到页帧时。
- 如果在涉及该页的I/O操作期间发生错误，则PG_error置位。
- PG_referenced和PG_active控制系统使用该页的活跃程度。
- PG_uptodate表示页的数据已经从块设备读取，其间没有出错。
- 如果与硬盘上数据相比，页的内容发生改变，则置位PG_dirty。
- PG_lru有助于实现页面回收和切换。内核使用两个最近最少使用链表来区别活动和不活动页。
- PG_highmem表示页在高端内存中，无法持久映射到内核内存中。
- 如果page结构的private成员非空，则必须设置PG_private位。用于I/O的页，可使用该字段将页细分为多个缓冲区。
- 如果页的内容处于向块设备回写的过程中，则需要设置PG_writeback位。
- 如果页是slab分配器的一部分，则设置PG_slab位。
- 如果页处于交换缓存，则设置PG_swapache。
- 在可用内存的数量变少时，内核试图周期性回收页，即剔除不活动、未用的页。
- 如果页空闲且包含在伙伴系统的列表中，则设置PG_buddy位，伙伴系统是页分配机制的核心。
- PG_compound表示该页属于一个更大的复合页，复合页由多个毗连的普通页组成。


内核定义一些标准宏，用于检查是否设置某个特定的比特位

- PageXXX(page)会检查页是否设置PG_xxx位。
- SetPageXXX在某个比特位没有设置的情况下，设置该比特位，并返回原值。
- ClearPageXXX无条件清除某个特定的比特位。
- TestClearPageXXX清除某个设置的比特位，并返回原值。

## 页表

层次化的页表用于支持对大地址空间的快速、高效管理。

页表管理分为两个部分，第一部分依赖于体系结构，第二部分是体系结构无关。

数据结构在头文件include/asm-arch/page.h和include/asm-arch/pgtable.h中找到。

### 数据结构

在C语言中，void *数据类型用于定义可能指向内存中任何字节位置的指针。内核源代码假定void *和unsigned long类型所需的比特位数相同，因此它们可以进行强制转换而不损失信息。

**内存地址的分解**

根据四级页表结构的需要，虚拟内存地址分为5个部分(4个用于选择页，1个索引表示页内位置)。

下图说明如何用比特位移来定义地址字各分量的位置。

![img](https://upload-images.jianshu.io/upload_images/17352405-f55146debdc0c1c7.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

- BITS_PER_LONG定义用于unsigned long变量的比特位数目，因而也适用于指向虚拟地址空间的通用指针。
- 每个指针末端的几个比特位，用于指定所选页帧内存的位置。比特位的具体数目由PAGE_SHIFT指定。
- PMD_SHIFT指定页内偏移量和最后一级页表所需比特位的总数。该值减去PAGE_SHIFT，可得最后一级页表项索引所需比特位的数目。
- PUD_SHIFT由PMD_SHIFT加上中间层页表索引所需的比特位长度，而PGDIR_SHIFT则由PUD_SHIFT加上上层页表索引所需的比特位长度。
- 对全局页目录中的一项所能寻址的部分地址空间长度计算以2为底的对数，即为PGDIR_SHIFT。

n比特位长的地址字可寻址底地址区域长度为 `2^n` 字节。内核定义额外的宏变量保存计算得到的值

```c
#define PAGE_SIZE		(1UL << PAGE_SHIFT)
#define PUD_SIZE		(1UL << PUD_SHIFT)
#define PMD_SIZE		(1UL << PMD_SHIFT)
#define PGDIR_SIZE		(1UL << PGDIR_SHIFT)
```

值 `2^n` 在二进制中很容易通过位置0左移n位计算而得到。

内核需要一种方法从给定地址中提起各个分量。内核使用如下定义的位掩码来完成该工作。

```c
#define PAGE_MASK		(~(PAGE_SIZE-1))
#define PUD_MASK		(~(PUD_SIZE-1))
#define PMD_MASK		(~(PMD_SIZE-1))
#define PGDIR_MASK		(~(PGDIR_SIZE-1))
```

将给定地址与对应掩码按位与即可。

**页表的格式**

上述定义确立了页表项的数目，没有定义结构。内核提供四个数据结构(page.h)表示页表项的结构

- pgd_t用于全局页表目录项
- pud_t用于上层页目录项
- pmd_t用于中间页目录项
- pte_t用于直接页表项

用于分析页表项的函数

|  pgd_val   | 将pte_t等类型的变量转换为unsigned long整数 |
| :--------: | :----------------------------: |
|  pud_val   |              ···               |
|  pmd_val   |              ···               |
|  pte_val   |              ···               |
| pgprot_val |              ···               |

|  __pgd   | pgd_val等函数的逆：将unsigned long整数转换为pgd_t等类型的变量 |
| :------: | :--------------------------------------: |
|  __pud   |                                          |
|  __pmd   |                                          |
|  __pte   |                                          |
| __pgprot |                                          |

| pgd_index | 从内存指针和页表项获得下一级页表的地址 |
| :-------: | :-----------------: |
| pud_index |                     |
| pmd_index |                     |
| pte_index |                     |

| pgd_present | 检查对应项的_PRESENT位是否设置，如果该项对应的页表或页在内存中，则会置位 |
| :---------: | :--------------------------------------: |
| pud_present |                                          |
| pmd_present |                                          |
| pte_present |                                          |

| pgd_none | 对xxx_present函数的值逻辑取反。如果返回ture，则检查的页不在内存中 |
| :------: | :--------------------------------------: |
| pud_none |                                          |
| pmd_none |                                          |
| pte_node |                                          |

| pgd_clear | 删除传递的页表项，通常是将其设置为零 |
| :-------: | :----------------: |
| pud_clear |                    |
| pmd_clear |                    |
| pte_clear |                    |

| pgd_bad | 检查中间层页表、上层页表、全局页表的项是否无效。如果函数从外部接收输入参数，则无法假定参数是有效的。为保证安全性，可以调用这些函数进行检查 |
| :-----: | :--------------------------------------: |
| pud_bad |                                          |
| pmd_bad |                                          |

| pmd_page | 返回保存页数据的page结构或中间页目录的项 |
| :------: | :--------------------: |
| pud_page |                        |
| pte_page |                        |

虚拟地址分为几个部分，用作各个页表的索引。根据使用的体系结构字长不同，各个单独的部分长度小于32或64个比特位。这意味着并非表项的所有比特位都存储了有用的数据，即下一级表的基地址。多余的比特位用于保存额外的信息。

**特定于PTE的信息**

最后一级页表中的项不仅包含了指向页的内存位置的指针，还在上述的多余比特位包含与页有关的附加信息。

- _PAGE_PRESENT指定虚拟内存页是否存在于内存中。页可能换出到交换区，如果页不再内存中，那么页表项的结构通常会有所不同，因为不需要描述页在内存中的位置。相反，需要信息来标识并找到换出的页。
- CPU每次访问页时，会自动设置_PAGE_ACCESSED。内核会定期检查该比特位，以确认页使用的活跃程度。在读或写访问之后设置该比特位。
- _PAGE_DIRTY表示是否是“脏的”，即页的内容是否已经修改过。
- _PAGE_FILE的数值与 _PAGE_DIRTY相同，但用于不同的上下文，即页不在内存中的时候。
- 如果设置 _PAGE_USER，则允许用户空间代码访问该页。否则只有内核才能访问(或CPU处于系统状态的时候)
- _PAGE_READ 、_PAGE_WRITE和_PAGE_EXECUTE指定普通用户进程是否允许读取、写入、执行该页的机器代码。
- IA-32和AMD64提供了_PAGE_BIT_NX，用于将页标记为不可执行功能时，才能使用该保护位。例如，可以防止执行栈页上的代码。否则，恶意代码可能通过缓冲区溢出手段在栈上执行代码。

每种体系结构都必须提供两个东西

- 使得内存管理子系统能够修改pte_t项中额外的比特位，即保存额外的比特位的_pgprot数据类型
- 修改这些比特位的pte_modify函数

内核还定义各种函数，用于查询和设置内存页与体系结构相关的状态。

|      函数       |              描述               |
| :-----------: | :---------------------------: |
|  pte_present  |            判断页在内存中            |
|   pte_read    |          判断从用户空间读取该页          |
|   pte_write   |           判断可以写入到该页           |
|   pte_exec    |      判断该页中的数据可以作为二进制执行代码      |
|   pte_dirty   |        判断页是脏页，其内容是否修改过        |
|   pte_file    |         判断该页表项属于非线性映射         |
|   pte_young   |     判断访问位(_PAGE_ACCESS)设置     |
| pte_rdprotect |           清除与该页的读权限           |
| pte_wrprotect |           清除与该页的写权限           |
| pte_exprotect |        清除执行该页中二进制数据的权限        |
|  pte_mkread   |             设置读权限             |
|  pte_mkwrite  |             设置写权限             |
|  pte_mkexec   |           允许执行页的内容            |
|   pte_mkdir   |            将页标记为脏             |
|  pte_mkclean  |    清除页，通常是指清除_PAGE_DIRTY位     |
|  pte_mkyoung  | 设置访问位，在大多数体系结构上是_PAGE_ACCESSD |
|   pte_mkold   |             清除访问位             |

这些函数，分别用于设置、删除、查询某个特定的属性(例如，页的写入权限)。内核假定页面数据的访问可以按3种不同的方式控制。即读、写和执行权限。

### 页表项的创建和操作

用于创建新页表项的函数

|    函数     |                描述                |
| :-------: | :------------------------------: |
|  mk_pte   | 创建一个页表项。必须将page实例和所需的页访问权限作为参数传递 |
| pte_page  |       获得页表项描述的页对应的page实例地址       |
| pgd_alloc |   分配并初始化可容纳一个完整页表的内存(不只是一个表项)    |
| pud_alloc |                                  |
| pmd_alloc |                                  |
| pte_alloc |                                  |
| pgd_free  |            释放页表占据的内存             |
| pud_free  |                                  |
| pmd_free  |                                  |
| pte_free  |                                  |
|  set_pgd  |            设置页表中某项的值             |
|  set_pud  |                                  |
|  set_pmd  |                                  |
|  set_pte  |                                  |

所有体系结构都必须实现表中的函数，以便内存管理代码创建和销毁页表

## 初始化内存管理

### 建立数据结构

对相关数据结构的初始化是从全局启动例程start_kernel中开始，该例程在加载内核并激活各个子系统之后执行。由于内存管理是内核一个非常重要的部分，因此在特定于体系结构的设置步骤中检测内存并确定系统中内存的分配情况后，会立即执行内存管理的初始化。

**先决条件**

为确保内存管理代码是可移植的，内核在mm/page_alloc.c中定义一个pg_data_t实例管理所有的系统内存。

**系统启动**

start_kernel的代码流程。其中只包含与内存管理相关的系统初始化函数。

![img](https://img-blog.csdn.net/20130814204707656?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZ29vZGx1Y2t3aGg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

- setup_arch是一个特定于体系结构的设置函数，其中一项任务是负责初始化自举分配器
- 在SMP系统上，setup_per_cpu_areas初始化源代码中定义静态per-cpu变量，这种变量对系统中的每个CPU都有一个独立副本。setup_per_cpu_areas的目的是为系统的各个CPU分别创建一份这些数据的副本。在非SMP系统上该函数是一个空函数。
- build_all_zonelists建立结点和内存域的数据结构
- mem_init是另一个特定于体系结构的函数，用于停用bootmem分配器并迁移到实际内存管理函数
- kmem_cache_init初始化内核内存用于小块内存区的分配器
- setup_per_cpu_pageset从上文提到的struct zone，为pageset数组的第一个数组元素分配内存。该函数还负责设置冷人分配器的限制。

**结点和内存域初始化**

build_all_zonelists建立管理结点及其内存域所需的数据结构。该函数可以通过引入的宏和抽象机制实现，而不用考虑具体的NUMA和UMA系统。

假定需要根据编译时配置，以不同方式执行某一个任务。一种可能的方法是，使用两个不用的函数，每次调用时，根据某些预处理器条件来选择正确的一个

```c
void do_something{
  ...
  #ifdef CONFIG_WORK_HARD
  	do_work_fast();
  #else
  	do_work_at_your_leisure();
  #endif
  ...
}
```

更优雅的一个方案是根据选择的不同配置，来定义函数

```c
#ifdef CONFIG_WORK_HARD
void do_work(){
  ...
}
#else
void do_work(){
  ...
}
```

build_all_zonelists将所有工作都委托给__build_all_zonelists，后者对系统中的各个NUMA结点分别调用build_zonelists。

由于UMA系统只有一个结点，build_zonelists只调用了一次，就对所有的内存创建了内存域列表。NUMA系统调用该函数的次数等同于结点的数目。

build_zonelists需要一个指向pgdat_t实例的指针作为参数。该函数的任务是，在当前处理的结点和系统中其他结点的内存域之间建立一种等级次序。接下来，依据这种次序分配内存。

例如，其中内核想要分配高端内存。它首先企图在当前结点的高端内存域找到一个大小适当的空闲段。如果失败，则查看该结点的普通内存域，如果还失败，则试图在该结点的DMA内存域执行分配。如果在3个本地内存域都无法找到空闲内存，则查看其它结点。在这种情况下，备选结点应该尽可能靠近主结点，以最小化由于访问非本地内存引起的性能损失。

内核使用pg_data_t中的zonelist数组，来表示所描述的层次结构。

```C
typedef struct pglist_data{
  ...
  	struct zonelist node_zonelists[MAX_ZONELISTS];
}pg_data_t;

#define MAX_ZONES_PER_ZONELIST (MAX_NUMNODES * MAX_NR_ZONES)
struct zonelist{
  ...
  	struct zone * zones[MAX_ZONES_PER_ZONELIST + 1];
};
```

node_zonelists数组对每种可能的内存域类型，都配置了一个独立的数组项。数组项包含了类型为zonelist的一个备用列表。

备用列表的各项是借助于zone_type参数排序的，该参数指定了最优先选择哪个内存域，该参数的初始值是外层循环的控制变量i。其值可能是ZONE_HIGHMEM、ZONE_NORMAL、ZONE_DMA或ZONE_DMA32之一。nr_zone表示从备用列表中的哪个位置开始填充新项。

### 特定于体系结构的设置

**内核在内存中的布局**

![img](https://img-blog.csdn.net/20130814204853546?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZ29vZGx1Y2t3aGg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

该图给出物理内存的前几兆字节，具体的长度依赖于内核二进制文件的长度。

- 前4KiB是第一个页帧，一般会忽略，因为通常保留在BIOS使用
- 接下来640KiB原则上是可用的，但也不用于内核加载。原因：该区域之后紧邻的区域由系统保留，用于映射各种ROM。

内核占据的内存分为几段，其边界保存在变量中

- _text 和 _etext 是代码段的起始和结束地址，包含编译后的内核代码
- 数据段位于 _etext和 _edata之间，保存了大部分内核变量
- 初始化数据在内核启动过程结束后不需要保存在最后一段，从 _edata 到 _end。

每次编译内核时，都生成一个文件System.map并保存在源目录下。地址值都偏移0XC0000000，这是在用户和内核地址之间采用标准的3：1划分时，内核段的起始地址。

**初始化步骤**

在内核已经载入内存，而初始化的汇编程序部分已经执行完毕后，内核执行的操作步骤

imgTODO

- 首先调用machine_specific_memory_setup，创建一个列表，包括系统占据的内存区和空闲内存区
- 内核接下来用parse_cmdline_early分析命令行，主要关注"mem=XXX[KkmM]、highmem=XXX[KkmM]"
- setup_memory函数有两个版本，一个用于连续内存系统，另一个用于不连续内存系统。
  - 确定(每个结点)可用的物理内存页的数目
  - 初始化bootmem分配器
  - 接下来分配各种内存区。例如，运行第一个用户空间所需的最初的RAM磁盘
- paging_init初始化内核页表并启用内存分页。通过调用pagetable_init，确保直接映射到内核地址空间的物理内存被初始化。
- 调用zone_sizes_init会初始化系统中所有结点的pgdat_t实例。
  - 首先使用add_active_range，对可用的物理内存建立一个相对简单的列表。
  - 体系结构无关的函数free_area_init_nodes接下来使用该信息建立完备的内核数据结构。

**分页机制的初始化**

paging_init负责建立智能用于内核的页表，用户空间无法访问。

内核通常将总的4GiB可用虚拟地址空间按3：1比例划分，这些划分的主要动机是

- 在用户应用空间执行切换到核心态时，内核必须装载在一个可靠的环境中。因此有必要将地址空间的一部分分配给内核专用
- 物理内存页则映射到内核地址空间的起始处，以便内核直接访问，无需复杂的页表操作。

虽然用于用户层进程的虚拟地址部分随进程切换而改变，但是内核部分总是相同的。

 ![1574044760(1)](resources\1574044760(1).jpg)

**地址空间的划分**

按3：1的比例划分地址空间，只是约略反映内核中的情况，内核地址空间自身又分为各个段。

 ![1574044857(1)](resources\1574044857(1).jpg)

1. 地址空间的第一段用于将系统的所有物理内存页映射到内核的虚拟地址空间中。由于内核地址空间从偏移量0XC0000000开始，即3GiB。每个虚拟地址x都对应物理地址x - 0XC0000000，是一个线性平移。
2. 直接映射区域从0XC0000000到high_memory地址。如果物理内存超过896MiB，则内核无法直接映射全部物理内存，小于最大限制1GiB。因此内核必须保留地址空间最后的128MiB用于其他目的。内核经常使用normal和highmem，来区分是否可以直接映射的页帧。

内核地址空间的最后128Mi的3个用途

1. 虚拟内存中连续、但物理内存中不连续的内存区，可以在vmalloc区域分配。
2. 持久映射用于将高端内存域中的非持久页映射到内核中。
3. 固定映射是与物理地址空间中的固定页关联的虚拟地址空间项，但具体关联的页帧可以自由选择。

内存划分常数

- 直接映射的边界由high_memory指定。如果启用了高端内存支持，则high_memory表示两个内存区之间的边界，总是896MiB。
- VMALLOC_START和VMALLOC_END定义了vmalloc区域的开始和结束。用于物理上不连续的内核映射。
- PKMAP_BASE定义起始地址(这里是相对于固定映射区域进行计算的)，LAST_PKMAP定义容纳映射所需的页数。
- 固定映射地址，指向物理内存中的随机位置。相对于内核空间起始处的线性映射，在该映射内部的虚拟地址和物理地址之间的关联不是预设的，而可以自由定义。

**备选划分方式**

将虚拟地址空间按3：1比例划分不是唯一的选项。在某些场合可能最好将地址空间对称划分，2：2的形式。那么_PAGE_OFFSET必须设置为0X80000000。

虚拟地址空间的不同划分比例，以及一致性物理内存的最大数量

|  比例   | CONFIG_PAGE_OFFSET | MAXMEM(MiB) |
| :---: | :----------------: | :---------: |
|  3：1  |     0XC0000000     |     896     |
| ≈ 3：1 |     0XB0000000     |    1152     |
|  2：2  |     0X80000000     |    1920     |
| ≈ 2：2 |     0X78000000     |    2048     |
|  1：3  |     0X40000000     |    2944     |

**划分虚拟地址空间**

调用paging_init划分虚拟地址空间，代码流程

 ![1574048182(1)](resources\1574048182(1).jpg)

1. pagetable_init首先初始化系统的页表，以swapper_pg_dir为基础。接下来启用两个扩展。
   - 对超大内存页的支持。这些特别标记的页，其长度为4MiB，而不是普通的4KiB。增加页大小，页表项变少，可以减少其中来自内核的缓存项
   - 如有可能，内核页会设置另一个属性(_PAGE_GLOBAL)。在上下文切换期间，设置 _PAGE_GLOBAL位的页，对应的TLB缓存项不从TLB刷出。内核总是出现于虚拟地址空间同样的位置，提高了系统性能。
2. 借助于kernel_physical_mapping_init，将物理内存页映射到虚拟地址空间中从PAGE_OFFSET开始的位置。
3. 接下来建立固定映射和持久内核映射对应的内存区。在用pagetable_init完成页表初始化之后，则将cr3寄存器设置为指向全局页目录的指针。
4. _flush_all_tlb刷出启东市分配的一些内存地址数据。
5. kmap_init初始化全局变量kmap_pte。从高端内存域将页映射到内核地址空间中，会使用该变量存入相应内存区的页表项。

**冷热缓存的初始化**

zone_pcp_init负责初始化缓存。该函数由free_area_init_nodes调用。

```c
static __devinit void zone_pcp_init(struct zone *zone){
  int cpu;
  unsigned long batch = zone_batchsize(zone);
  
  for(cpu = 0; cpu < NR_CPUS; cpu++){
    setup_pageset(zone_pcp(zone,cpu),batch);
  }
  if(zone -> present_pages){
    printk(KERN_DEBUG "%s zone:%lu pages, LIFO batch:%lu\n",zone->name,zone->present_pages,batch);
  }
}
```

在用zone_batchsize算出批量大小后，代码将遍历系统中的所有CPU，同时调用setup_pageset填充每个per_cpu_pageset实例的常亮。在调用该函数时，使用了zone_pcp宏来选择与当前CPU相关的内存域的pageset实例。

  ![1574064619(1)](resources\1574064619(1).jpg)

- 对热页来说，下限为0，上限为`6*batch`，缓存中页的平均数量大约是 `4*batch`，因为内核不会让缓存水平降到太低。
- 冷页列表的水印稍微低一些，因为冷页并不放置到缓存中。只用于一些不太关注性能的操作。其上限是batch值的两倍。

在zone_pcp_init结束时，会输出各个内存域的页数以及计算出的批量大小。

**注册活动内存区**

内核版本必须根据不同的体系结构来建立所需的数据结构，但具体的方法随时间的推移已经越来越模块化。各个体系结构只须注册所有活动内存区的一个简单表，通用代码则据此生成主数据结构。

活动内存区就是不包含空洞的内存区。必须使用add_active_range在全局变量early_node_map中注册内存区。

在注册两个毗连的内存区时，add_active_regions会确保将它们合并为一个。此外，该函数不提供其他额外的功能特性。

1)在IA-32系统上由zone_size_init调用，2)在AMD64系统上由e820_register_active_regions调用

**AMD64地址空间的设置**

AMD64系统当前只实现一个比较小的物理地址空间，地址字宽度为48位。这在不失灵活性的前提下，简化并加速地址转换。48位宽的地址字可以寻址256TiB的地址空间，或256x1024GiB。

物理地址字位宽被限制在48位，但在寻址虚拟地址空间时仍然使用64位指针。很显然，处理器必须隐藏对未实现地址空间的访问。一种可能的做法是，禁止使用超出物理地址空间的虚拟地址。但硬件设计师选择不同的方法。其解决方法基于所谓的符号扩展

 ![1574084135(1)](resources\1574084135(1).jpg)

虚拟地址的低47位，即[0, 46]，可以任意设置。而比特位[47, 63]的值总是相同：或者全0，或者全1。

因此整个地址空间划分为3部分：下半部，上半部，二者之间的禁用区。

对于将虚拟地址空间划分为两部分，内核没有什么担忧的。内核在大多数体系结构上都依赖于将地址空间划分为内核空间和用户空间两部分。

 ![1574084386(1)](resources\1574084386(1).jpg)

可访问的地址空间的整个下半部用作用户空间，而整个上半部专用于内核。由于两个空间都极大，无须调整划分比例之类的参数。

内核地址空间的空洞，防止偶然访问地址空间的非规范部分。如果发生这种情况，处理器引发一个一般性保护异常。

### 启动过程器件的内存管理

在启动过程期间，尽管内存管理尚未初始化，但内核仍然需要分配内存以创建各种数据结构。bootmem分配器用于在启动阶段早期分配内存。

内核实现一个最先适配(first-fit)分配器用于在启动阶段管理内存：该分配器使用一个位图来管理页，位图比特位的数目与系统中物理内存页的数目相同。比特位为1，表示已用页；比特位为0，表示空闲页。

在需要分配内存时，分配器逐位扫描位图，直到找到一个能提供足够连续页的位置，所谓的最先最佳/最先适配位置。

**数据结构**

内核提供一个bootmem_data结构的实例，用于最先适配分配器管理的一些数据。

```c
typedef struct bootmem_data{
  unsigned long node_boot_start;
  unsigned long node_low_pfn;
  void *node_bootmem_map;
  unsigned long last_offset;
  unsigned long last_pos;
  unsigned long last_success;
  
  struct list_head list;
}bootmem_data_t;
```

在下面提到页时，总是指物理页帧

- node_boot_start保存系统中第一页的编号，大多数体系结构下都是零。
- node_low_pfn是可以直接管理的物理地址空间中最后一页的编号。
- node_bootmem_map是指向存储分配位图的内存区的指针。
- last_pos是上一次分配的页的编号。如果没有请求分配整个页，则last_offset用作该页内部的偏移量。
- last_success指定位图上一次成功分配内存的位置，新的分配将由此开始。
- 内核不连续的系统可能需要多个bootmem分配器。NUMA计算机，其中每个结点注册一个bootmem分配器，但如果物理地址空间散布着空洞，也可以为每个连续内存区注册一个bootmem分配器。

**初始化**

bootmem分配器的初始化是一个特定于体系结构的过程，此外还取决于计算机的内存布局。

IA-32系统：

 ![1574085455(1)](resources\1574085455(1).jpg)

AMD64系统：

 ![1574085485(1)](resources\1574085485(1).jpg)

- 首先bootmem_bootmap_bitmap计算bootmem位图所需页的数目
- 然后使用init_bootmem将信息填充到体系结构无关的bootmem数据结构中
- free_bootmem_with_active_regions可以再次使用e820映射中的信息，按照BIOS报告的使用情况，释放所有实际空闲的内存区
- 调用一次reserve_bootmem注册bootmem分配位图所需的空间

**对内核的接口**

**1.分配内存**

内核提供各种函数，用于在初始化期间分配内存。

1. alloc_bootmem(size)和alloc_bootmem_pages(size)按指定大小在ZONE_NORMAL内存域分配内存。数据是对齐的，这使得内存或者从可适用于L1高速缓存的理想位置开始，或者从页边界开始
2. alloc_bootmem_low和alloc_bootmem_low_pages的工作方式类似于上述函数，只是从ZONE_DMA内存域分配内存
3. _alloc_bootmem_core函数实现最先适配算法。执行的操作
   - 从goal开始，扫描位图，查找满足分配请求的空闲内存区
   - 如果目标页紧接着上一次分配的页，即bootmem -> last_pos，内核会检查bootmem_data -> last_offset，判断所需的内存能否在上一页分配或从上一页开始分配
   - 新分配的页在位图对应的比特位设置为1。最后一页的数目也保存在bootmem_data -> last_pos

**2.释放内存**

内核提供free_bootmem函数来释放内存。它需要两个参数：需要释放的内存区的起始地址和长度。

函数将工作委托给_free_bootmem_core。只能释放整页，因为bootmem分配器没有保存有关页划分的任何信息。

_free_bootmem_core首先计算完全包含在该内存区中、将被释放的页。只有部分包含在内存区中的页将被忽略。位图中对应的项设置为0，完成页的释放。

**停用bootmem分配器**

在系统初始化进行到伙伴系统分配器能够承担内存管理的责任后，必须停用bootmem分配器，毕竟不能同时用两个分配器管理内存。

在UMA和NUMA系统上，停用分别由free_all_bootmem和free_all_bootmem_node完成。

首先扫描bootmem分配器的页位图，释放每个未用的页。到伙伴系统的接口的是__free_pages+bootmem函数，该函数对每个空闲页调用。在页位图已经完全扫描之后，它占据的内存空间也必须释放。此后，只有伙伴系统可用于内存分配。

**释放初始化数据**

许多内核代码块和数据表只在系统初始化阶段需要。例如，对于链接到内核中的驱动程序而言，则不必要在内核内存中保持其数据结构的初始化例程。在结构建立之后，这些例程就不再需要了。

内核提供两个属性(` __init 和 __initcall`) 用于标记初始化函数和数据。初始化函数的实现背后，其一般性的思想是，将数据保持在内核映像的一个特定部分，在启动结束时可以完全从内存删除。

```c
#define __init		__attribute__		((__section__ (".init.text")))	__cold
#define __initcall	__attribute__		((__section__ (".init.data")))
```

`__attribute__ ` 是一个特殊的GNU C关键字。`__section__` 属性用于通知编译器将随后的数据或函数分配写入二进制文件的 .init.text和 .init.data 段。

为从内存中释放初始化数据，内核不必知道数据的性质，即哪些数据和函数保存在内存中和它们的用于都是完全不相干的。唯一相关的信息是这些数据和函数在内存那种开始和结束的地址。

free_initmem负责释放用于初始化的内存区，并将相关的页返回给伙伴系统。在启动过程刚好结束时会调用该函数，紧接着init作为系统中第一个进程启动。

## 物理内存的管理

在内核初始化完成后，内存管理的责任由伙伴系统承担。伙伴系统基于一种相对简单然而强大算法。它结合优秀内存分配器的两个关键特征：速度和效率。

### 伙伴系统的结构

系统内存中的每个物理内存页(页帧)，都对应于一个struct page实例。每个内存域都关联了一个struct zone实例，其中保存用于管理伙伴数据的主要数组。

```c
struct zone{
  ...
  /*
  * 不同长度的空闲区域
  */
  struct free_area	free_area[MAX_ORDER];
  ...
};
```

free_area是一个辅助数据结构，定义如下：

```c
struct free_area{
  struct list_head free_list[MIGRATE_TYPES];
  unsigned long nr_free;
};
```

nr_free指定当前内存区中空闲页块的数目。free_list是用于连接空闲页的链表。

阶是伙伴系统中，描述内存分配的数量单位。内存块的长度是 `2^order`, 其中order的范围从0到MAX_ORDER。该常数通常设置为11，一次分配可以请求的页数最大是 `2^11 = 2048`。

free_area[]数组中各个元素的索引也解释为阶，用于指定对应链表中的连续内存区包含多少个页帧。第0个链表包含的内存区为单页( `2^0` )，第1个链表管理的内存区为两页( `2^1`)，第3个管理的内存区为4页，依次类推。

内存区连接：内存区中第1页内的链表元素，可用于将内存区维持在链表中。因此，也不必引入新的数据结构来管理物理上连续的页，否则这些页不可能在同一内存区中。

 ![1574153430(1)](resources\1574153430(1).jpg)

伙伴不必是彼此连接的。如果一个内存区在分配其间分解为两半，内核会自动将未用的一半假如到对应的链表中。如果在未来的某个时刻，由于内存释放的缘故，两个内存区都处于空闲状态，可通过其地址判断是否为伙伴。

基于伙伴系统的内存管理专注于某个结点的某个内存域，在首选的内存域结点无法满足分配请求时，首先尝试同一结点的另一内存域，接下来尝试另一个结点。直至满足请求。

 ![1574153669(1)](resources\1574153669(1).jpg)

### 避免碎片

**依据可移动性组织页**

在Linux内存管理方面，有一个长期存在的问题：在系统启动并长期运行后，物理内存会产生很大碎片。

 ![1574216205(1)](resources\1574216205(1).jpg)

假定内存由60页组成，用于示例足够。左侧的地址空间中散布着空闲页。尽管大约25%的物理内存仍然未分配，但最大的连续空闲区只有一页。这对用户空间应用程序没有问题：其内存通过页表映射，无论空闲页在物理内存的分布如何，应用程序看到的内存似乎总是连续的。右图给出的情形，空闲页和使用页的数目与左图相同，但所有空闲页都位于一个连续区中。

但对内核来说，碎片是一个问题。由于(大多数)物理内存一致映射到地址空间的内核部分，那么在左图的场景中，无法映射比一页更大的内存区。尽管许多时候内核都分配的是比较小的内存，但也有时候需要分配多于一页的内存。

在大部分内存仍然未分配时，就也可能发生碎片问题。下图只分配4页，但可分配的最大连续区只有8页，因为伙伴系统所能工作的分配范围只有2的幂次。

 ![1574216755(1)](resources\1574216755(1).jpg)

物理内存页不能移动到任意位置，。内核使用反碎片，试图从最初开始尽可能防止碎片

内核将已分配页划分为3种类型

- 不可移动页：在内存中有固定位置，不能移动到其他地方。例如，核心内核分配的大多数内存。
- 可回收页：不能直接移动，但可以删除，其内容可以从某些源重新生成。例如，映射自文件的数据。
- 可移动页：可以随意地移动。属于用户空间应用程序的页。

内核使用的反碎片技术，即基于将具有相同可移动性的页分组，将其分配到不同的列表中。

**1.数据结构**

内核定义一些宏来定义不同的迁移类型

```c
#define MIGRE_UNMOVABLE 	0
#define MIGRE_RECLAIMABLE 	1
#define MIGRE_MOVABLE		2
#define MIGRE_RESERVE		3
#define MIGRE_ISOLATE		4 /* 不能从这里分配 */
#define MIGRE_TYPES			5
```

MIGRE_TYPES只是表示迁移乐行的数目，也不代表具体的区域。

对伙伴系统数据结构的主要调整，是将空闲列表分解为MIGRE_TYPES个列表：

```c
struct free_area{
  struct list_head free_list[MIGRE_TYPES];
  unsigned long nr_free;
};
```

nr_free统计所有列表上空闲页的数目，而每种迁移类型都对应于一个空闲列表。宏for_each_migratetype_order(order, type)可用于迭代指定迁移类型的所有分配阶。

**2.全局变量和辅助函数**

尽管页可移动性分组特性总是编译到内核中，但只有在系统中有足够内存可以分配到多个迁移类型对应的链表时，才有意义。 由于每个迁移链表都应该有适当数量的内存，内核需要定义"适当"的概念。

这是通过两个全局变量pageblock_order和pageblock_nr_pages提供的。

pageblock_order表示内核认为是“大”的一个分配阶；

pageblock_nr_pages表示该分配阶对应的页数；

如果各迁移类型的链表中没有一块较大的连续内存，那么页面迁移不会提供任何好处，因此在可用内存太少时内核会关闭该特性。

分配类型属于何种迁移类型：内核提供两个标志，分别用于标识分配的内存是可移动的(`_GFP_MOVABLE`)或可回收的(`_GFP_RECLAIMABLE`)。如果这些标志没有设置，则分配的内存假定为不可移动的。

**3.初始化基于可移动性的分组**

在内存子系统初始化期间，memmap_init_zone负责处理内存域的page实例。所有的页最初都标记为可移动的。

在分配内存时，如果必须盗取不同于预计迁移类型的内存区，内核在策略上倾向于盗取更大的内存区。由于所有页最初都是可移动的，那么在内核分配不可移动的内存区时，则必须盗取。

实际上，在启动器件分配可移动内存区的情况较少，分配器有很高的几率分配长度最大的内存区，并将其从可移动列表转换到不可移动列表。由于分配的内存区长度是最大的，因此不会向可移动内存中引入碎片。

**虚拟可移动内存域**

除了可移动性组织页是防止物理内存碎片的一种方法，内核还提供了另一种阻止该问题的手段：虚拟内存域ZONE_MOVABLE。

基本思想：可用的物理内存划分为两个内存域，一个用于可移动分配，一个用于不可移动分配。这会自动防止不可移动页向可移动内存域引入碎片。

**1.数据结构**

kernelcore参数用来指定用于不可移动分配的内存数量，即用于既不能回收也不能迁移的内存数量，剩余的内存用于可移动分配。

ZONE_MOVALBE内存域位于高端或普通内存域：

```c
enum zone_type{
  ...
  	ZONE_NORMAL
 #ifdef CONFIG_HIGHMEM
 	ZONE_HIGHMEM,
 #endif
 	ZONE_MOVABLE,
 	MAX_NR_ZONE
};
```

ZONE_MOVABLE不关联到任何硬件上有意义的内存范围。

辅助函数find_zone_movable_pfns_for_nodes用于计算进入ZONE_MOVABLE内存数量、

从物理内存域提取多少内存用于ZONE_MOVABLE的问题，必须考虑下面两种情况：

- 用于不可移动分配的内存会平均分布到所有内存结点上
- 只使用来自最高内存域的内存。在内存较多的32位系统上，通常会是ZONE_HIGHMEM。对于64位系统，将使用ZONE_NORMAL或ZONE_DMA32。

实际上其作用的结果：

- 用于为虚拟内存域ZONE_MOVABLE提取内存页的物理内存域，保存在全局变量movable_zone中；
- 对每个结点来说，zone_movable_pfn[node_id]表示ZONE_MOVABLE在movable_zone内存域中锁取得内存的起始地址；

### 初始化内存域和结点数据结构

体系结构相关代码需要在启动期间建立以下信息：

- 系统中各个内存域的页帧边界，保持在max_zone_pfn数组；
- 各结点页帧的分配情况，保存在全局变量early_node_map中

**1.管理数据结构的创建**

内核提供一个通用框架，用于将上述信息转换为伙伴系统预期的结点和内存域数据结构。只需要建立简单结构，将繁重的工作留给free_area_init_node即可。

free_area_init_node流程图：

 ![1574304940(1)](resources\1574304940(1).jpg)

free_area_init_node首先必须分析并改写特定于体系结构的代码提供的信息。其中，需要对照zone_max_pfn和zone_min_pfn中指定的内存域的边界，计算各个内存域可使用的最低和最高的页帧编号。

free_area_init_node将该信息转化为一种更方便的表示形式，即以[low, high]形式描述各个内存域的页帧区间，存储在全局变量中。

接下来构建其他内存域的页帧区间，方法很直接：第n个内存域的最小页帧，即前一个(第n-1个)内存域的最大页帧。当前内存域的最大页帧由max_zone_pfn给出。

**2.对各个结点创建数据结构**

在内存域边界已经确定之后，free_area_init_nodes分别对各个内存域调用free_area_init_node创建数据结构。

辅助函数：

- calculate_node_totalpages首先累计各个内存域的页数，计算结点中页的总数。
- alloc_node_mem_map负责初始化一个简单但非常重要的数据结构。系统中各个物理内存页，都对应一个struct page实例。该结构的初始化由alloc_node_mem_map执行。
- 初始化内存域数据结构涉及的繁重工作由free_area_init_core执行，它会依次遍历结点的所有内存域

free_area_init_core剩余部分的任务是初始哈zone结构中的各个表头，并将各个结构成员初始化为0。调用两个辅助函数

- zone_pcp_init初始化该内存域的per-CPU缓存；
- init_currently_empty_zone初始化free_area列表，并将属于该内存域的所有page实例都设置为初始默认值。

### 分配器API

伙伴系统的接口而言，NUMA和UMA体系结构没有差别的，二者调用语法都是相同的。所有函数的一个共同点：只能分配2的整数幂个页。必须指定分配阶，伙伴系统将在内存中分配`2^order`。

- alloc_pages(mask, order)分配`2^order`页并返回一个struct page实例，表示分配的内存块的起始页；
- get_zored_page(mask)分配一页并返回一个page实例，页对应的内存填充0；
- `__get_free_pages(mask, order)` 和`__get_free_page(mask)` 的工作方式与上述函数相同，但返回分配内存块的虚拟地址，而不是page实例；
- get_dma_pages(gfp_mask, order)用来获得适用于DMA的页；

内核除了伙伴系统函数之外，还提供其他内核管理函数。

有4个函数用于释放不再使用的页，与所述函数稍有不同

- free_page(struct page *)和free_pages(struct page *, order)用于讲一个或`2^order`页返回给内存管理子系统。
- `__free_page(addr)`和`__free_pages(addr, order)`的语义类似于前两个函数，但在表示需要释放的内存区时，使用虚拟内存地址而不是page实例。

**1.分配掩码**

前述所有函数中强制使用的mask参数。Linux将内存分为内存域，内核提供**内存域修饰符**(在掩码的最低4个比特位)，来指定从哪个内存域分配所需的页。

```c
#define __GFP_DMA	((__force gfp_t)0x01u))
#define __GFP_HIGHMEM	((force gfp_t)0x02u)
#define __GFP_DMA32	((__force gfp_t)0x04u)
...
#define __GFP_MOVABLE	((__force gfp_t)0x100000u) /* 页是可移动的 */
```

内存域修饰符和扫描的内存域之间的关联

|              修饰符              |              扫描的内存域               |
| :---------------------------: | :-------------------------------: |
|          `__GFP_DMA`          |             ZONE_DMA              |
| `__GFP_DMA__` & `GFP_HIGHMEM` |             ZONE_DMA              |
|         __GFP_HIGHMEM         | ZOEN_HIGHMEM、ZONE_NROMAL、ZONE_DMA |
|               无               |       ZONE_NROMAL、ZONE_DMA        |

除了内存修饰符之外，掩码中还可以设置一些标志。

 ![1574320580(1)](resources\1574320580(1).png)

**2.内存分配宏**

通过使用标志、内存域修饰符好各个分配函数，内核提供一种非常灵活的内存分配体系。所有接口函数都可以追溯到一个简单的基本函数(alloc_pages_nodes)。

伙伴系统的各个分配函数之间的关系

 ![1574407693(1)](resources\1574407693(1).jpg)

类似的，内存释放函数也可以归约到一个主要的函数(__free_pages)，只是用不同的参数调用

 ![1574407766(1)](resources\1574407766(1).jpg)

### 分配页

所有API都追溯到alloc_pages_node。

```c
static inline struct page *alloc_pages_node(int nid, gfp_t gfp_mask,
											unsigned int order){
    if(unlikely(order >= MAX_ORDER))
    	return NULL;
    if(nid < 0){
      nid = muma_node_id();
    }	
    
    return __alloc_pages(gfp_mask, order,
    					NODE_DATA(nid) -> node_zonelists + gfp_zone(gfp_mask));
}
```

只执行一个简单的检查，避免分配过大的内存块。如果指定负的结点ID(不存在)，内核自动地使用当前执行CPU对应的结点ID。接下来的工作委托给__alloc_pages。

**1.选择页**

**辅助函数**

定义一些函数使用的标志，用于控制达到各个水印指定的临界状态时的行为。

```C
#define ALLOC_NO_WATERMARKS	0X01		/* 完全不检查水印 */
#define ALLOC_WMARK_MIN		0X02		/* 使用pages_min水印 */
#define ALLOC_WMARK_LON		0X04		/* 使用pages_low水印 */
#define ALLOC_WMARK_HIGH	0X08		/* 使用pages_high水印 */
#define ALLOC_HARDER		0X10		/* 试图更努力地分配，放宽限制 */
#define ALLOC_HIGH			0X20		/* 设置__gfp_high */
#define ALLOC_CPUSET		0X40		/* 检查内存结点是否对应着指定的CPU集合 */
```

默认情况下，只有内存域包含页的数目至少为zone->pages_high时，才能分配页。如果要使用较低(zone->pages_low)或最低(zone->pages_min)设置，则必须相应地设置ALLOC_WMARK_MIN或ALLOC_WMARK_LOW。ALLOC_HEADER通知伙伴系统在急需内存时放宽分配规则。

- 设置的标志在zone_watermark_ok函数中检查，该函数根据设置的标志判断是否能从给定的内存域分配内存
- get_page_from_freelist是伙伴系统使用的另一个重要的辅助函数。它通过标志集和分配阶来判断是否能进行分配
- 如果内存域使用与当前的分配请求，那么buffered_rmqueue试图从中分配所需数目的页

**分配控制**

__alloc_pages是伙伴系统的主函数。

该函数的实现，内核中比较冗长的部分，特别是在可用内存太少或逐渐用完时，函数就会复杂多

1. 最简单的情形中，分配空闲内存区只涉及调用一次get_page_from_freelist，然后返回所需数目的页

2. 如果无法找到空闲内存，内核再次遍历备用列表的所有内存域，每次都调用wakeup_kswapd，唤醒负责换出页的kswapd守护进程。空闲内存可以通过缩减内核缓存和页面回收获得，即写回或换出使用很少使用的页。

3. 如果失败，则判断设置PF_MEMALLOC或TIF_MEMDIE标志(内核不能处于中断上下文)，或再次调用get_page_from_freelist试图获得所需的页。但这次完全忽略水印。

   原因：

   1. 设置了 __GFP_NOMEMALLOC。该标志禁止使用紧急分配链表，因此无法在禁用水印的情况下调用get_page_from_freelist；
   2. 在忽略水印的情况下，get_page_from_freelist仍然失败。这种情况下，也会放弃搜索，报告错误消息。但如果设置了__GFP_NOFALL，内核会进入无限循环，首先等待(congestion_wait)块设备层结束占线，在回收页时可能出现这种情况，接下来再次尝试分配，直至成功；

4. 如果没有设置PF_MEMALLOC，内核仍然还有一些选项可以尝试，但这些都需要睡眠。

   - 内核通过cond_resched提供重调度时机
   - 分页机制提供一个目前尚未使用的选项，将很少使用的页换出到块介
   - 如果需要分配多页，那么per-CPU缓存中的页也会拿回到伙伴系统

**2.移除选择的页**

如果内核找到适当的内存域，具有足够的空闲页可供分配，那么还有两件事需要完成

1. 首先必须检查这些页是否连续的
2. 其次，必须按伙伴系统的方式从free_lists移除这些页，这可能需要分解并重排内存区

内核将工作委托给buffered_rmqueue。 ![1574925790(1)](resources\1574925790(1).jpg)

如果只分配一页，内核会进行优化，即分配阶为0的情形。该页不是从伙伴系统直接取得，而是取自per-CPU的页缓存。

如果需要分配多页，内核调用__rmqueue会从内存域的伙伴列表中选择适当的内存块。如有必要，该函数会自动分解大块内存，将未用的部分放回列表中。

所有失败情形都跳转到标号failed处理，这可以确保内核到达当前点之后，page指向一系列有效的页。

辅助函数prep_new_page对页进行几项检查，确保分配之后分配器处于理想状态。

 ![1574926311(1)](resources\1574926311(1).jpg)

**__rmqueue辅助函数**

该函数充当进入伙伴系统核心的看门人，根据传递进来的分配阶、用于获取页的内存域、迁移类型。`__rmqueue_smalles`扫描页的列表，直至找到适当的连续内存块。如果指定的迁移列表不能满足分配请求，则调用`__rmqueue_fallback`尝试其他的迁移列表。

如果需要分配的内存块长度小于所选择的连续页范围，即如果因为没有更小的适当内存块可用，而从较高的分配阶分配一块内存，那么该内存块必须按照系统伙伴的原理分裂成小的块。这是通过expand函数完成的。

expand函数使用了一组参数，page，zone，area语义都很显然。index指定该伙伴对在分配位图中的索引位置，low是预期的分配阶，high表示内存取自哪个分配阶。migratetype表示迁移类型。

 ![1575363342(1)](resources\1575363342(1).jpg)

1. size的值初始化为 `2^high`=`2^5`=32。分配的内存区已经在__rmqueue中从free_area列表移除，因此用虚线画出
2. 在第一遍循环中，内核切换到低一个分配阶，迁移类型相同的free_area列表，即阶为4.
3. 后一半内存区的地址可通过&page[size]计算。而page指针一直指向最初分配内存区的起始地址，并不改变。page指针指向的位置用箭头表示
4. 下一遍循环将剩余16页的后一半位置到对应于size = 8的free_area列表上。page仍然不动。

### 释放页

__free_pages是一个基础函数，用于实现内核API所有涉及内存释放的函数

 ![1575363830(1)](resources\1575363830(1).jpg)

首先判断所需释放的内存是单页还是较大的内存块
- 如果释放单页，则不还给伙伴系统，而是置于per-CPU缓存中，对很可能出现在CPU高速缓存的页，则放置到热页的列表中，调用free_hot_cold_page函数。
  - 如果free_hot_cold_page函数判断per-CPU缓存中页的数目超出了pcp->count，则将数量为pcp->batch的一批内存页还给伙伴系统。该策略称之为惰性合并。
  - 如果不超出惰性合并的限制，则页只是保存可以从per-CPU缓存中。但重要的是将private成员设置为页的迁移类型。


- 如果释放多个页，那么`__free_pages`将工作委托给`__free_pages_ok`，最后到`__free_one_page`。该函数不仅处理单页的函数，也处理复合页释放。


### 内核中不连续页的分配

**1.用vmalloc分配内存**

vmalloc是一个接口函数，内核代码使用它来分配在虚拟内存中连续但在物理内存中不一定连续的内存。

```c
void *vmalloc(unsigned long size);
```

使用vmalloc的实例是内核对模块的实现。因为模块可能在任何时候加载，如果模块数据比较多，那么无法保证有足够的连续内存可用，特别是在系统已经运行比较长时间的情况下。如果能够用小块内存拼接出足够的内存，那么使用vmalloc可以规避该问题。

vmalloc是内核出于自身的目的使用高端内存页的少数情形之一。

**数据结构**

```c
struct vm_struct{
  struct vm_struct 	*next;
  void				*addr;
  unsigned long 	size;
  unsigned long 	flags;
  struct page		**pages;
  unsigned int		nr_pages;
  unsigned long		phys_addr;
};
```

对于每个用vmalloc分配的子区域，都对应内核内存中一个该结构实例。

- addr定义了分配的子区域在虚拟地址空间中的起始地址。size表示该子区域的长度。
- flags存储了与该内存区关联的标志集合，这几乎是不可避免的。它只用于指定内存区类型，当前可选值有3个
  - VM_ALLOC指定了vmalloc产生的子区域
  - VM_MAP用于标识将现存pages集合映射到连续的虚拟地址空间中
  - VM_IOREMAP表示将几乎随机的物理内存映射到vmalloc区域中。
- pages是一个指针，指向page指针的数组。每个数组成员都表示一个映射到虚拟地址空间中的物理内存页的page实例
- phys_addr仅当用ioremap映射由物理地址描述的物理内存区域时才需要。
- next使得内核可以将vmalloc区域中的所有子区域保存在一个单链表上。


 ![1575444104(1)](resources\1575444104(1).jpg)

其中依次映射3个物理内存页，在物理内存中的位置分别是1023、725和7311。在虚拟的vmalloc区域中，内核将其看作起始于VMALLOC_START + 100的一个连续内存区。

**创建vm_area**

vm_area实例组成一个链表，管理vmalloc区域中已经建立的各个子区域。定义vmalloc的全局变量vmlist是表头。

内核在`vmalloc`提供辅助函数`get_vm_area`。它充当`__get_vm_area`的前端，负责参数准备工作。后一个函数负责实例工作的`__get_vm_area`函数的前端。根据子区域的长度信息，该函数试图在虚拟的vmalloc空间中找到一个适当的位置。

**分配内存区**

vmalloc发起对不连续的内存区的分配操作。该函数只是一个前端，为`__vmalloc`提供适当的参数，后者直接调用`__vmalloc_node`。

 ![1575446334(1)](resources\1575446334(1).jpg)

实现分为3部分

1. 首先，get_vm_area在vmalloc地址空间找到一个适当的区域；
2. 从物理内存分配各个页；
3. 最后将这些页连续地映射到vmalloc区域中

分配虚拟内存的工作就完成。

如果显式指定分配页帧的结点，则内核调用alloc_pages_node。否则，使用alloc_page从当前结点分配页帧。

**2.备选映射方法**

除了vmalloc之外，还有其他方法可以创建虚拟连续映射。

- vmalloc_32工作方式与vmalloc相同，但会确保所使用的物理内存总是可以用普通32位指针寻址。如果某种体系结构的寻址能力超出基于字长计算的范围，那么这种保证很重要。
- vmap使用一个page数组作为起点，来创建虚拟连续内存区。该函数所用的物理内存位置不是隐式分配的，而需要先行分配好，作为参数传递。此类映射可通过vm_map实例中的VM_MAP标志判断。
- 不同于上述的映射方法，ioremap是一个特定于处理器的函数，必须在所有体系结构上实现。它可以将取自物理地址空间、由系统总线用于I/O操作的一个内存块，映射到内核的地址空间中。

**3.释放内存**

有两个函数用于向内核释放内存，vfree用于释放vmalloc和vmalloc_32分配的区域，而vunmap用于释放由vmap或ioremap创建的映射。这两个函数都会归结到__vunmap。

 ![1575447954(1)](resources\1575447954(1).jpg)

### 内核映射

**1.持久内核映射**

如果需要将高端页帧长期映射(持久映射)到内核地址空间中，必须使用kmap函数。

- 没有启用高端支持，所有页都可以直接访问，因此只需要返回页的地址，无需显式创建一个映射
- 如果确实存在高端页，类似vmalloc，内核首先必须建立高端页和所映射到的地址之间的关联。还必须在虚拟地址空间中分配一个区域以映射页帧，最后，内核必须记录该虚拟区域的哪些部分在使用中，哪些仍是空闲的。

**数据结构**

内核在IA-32平台上在vmalloc区域之后分配一个区域，从PKMAP_BASE到FIXADDR_START。该区域用于持久映射。

内核利用下列数据结构，来建立物理内存页的page实例与其虚拟内存区中位置之间的关联：

```c
struct page_address_map{
  struct page *page;
  void *virtual;
  struct list_head list;
};
```

该结构用于建立page->virtual的映射。page是一个指向全局mem_map数组中的page实例的指针，virtual指定该页在内核虚拟地址空间中分配的位置。

 各数据结构之间的相互关系

 ![1575532379(1)](resources\1575532379(1).jpg)

**查找页地址**

page_address首先检查传递进来的page实例在普通内存还是高端内存。如果是前者，页地址可以根据page在mem_map数组中的位置计算。对于后者，可通过上述散列表查找虚拟地址。

**创建映射**

为通过page指针建立映射，必须使用kmap函数，用于确认指定的页是否确实在高端内存域中。否则，结构返回page_address得到的地址。如果确实在高端内存中，则内核将工作委托给kmap_high。

page_address函数首先检查是否已经映射，如果它不对应到有效地址，则必须使用map_new_virtual映射该页。该函数执行主要的步骤：

1. 从最后使用的位置开始，反向扫描pkmap_count数组，直至找到一个空闲位置。如果没有空闲位置，该函数进入睡眠状态，直至内核的另一部分执行解除映射操作腾出空位；
2. 修改内核的页表，将该页映射到指定位置。但尚未更新TLB。
3. 新位置的使用计数器设置为1.
4. set_page_address将该页添加到持久内核映射的数据结构。

**解除映射**

用kmap映射的页，如果不再需要，必须用kmap解除映射。

执行的操作

1. flush_cache_kmaps在内核映射上执行刷出，因为内核的全局页表已经修改。
2. 扫描整个pkmap_count数组。计数器值为1的项设置为0，从页表删除相关的项，最后删除该映射。
3. 最后，使用flush_tlb_kernel_range函数刷出所有与PKMAP区域相关的TLB项。

**2.临时内核映射**

kmap_atomic函数的一个主要优点是它比普通的kmap快速。但它不能用于可能进入睡眠的代码。因此，它对于很快就需要一个临时页的简短代码，是非常理想的。

**3.没有高端内存的计算机上的映射函数**

许多体系结构不支持高端内存，因此不需要该特性。

```c
#ifdef CONFIG_HIGHMEM
...
#else
static inline void *kmap(struct page *page){
  might_sleep();
  return page_address(page);
}

#define kunmap(page) do{(void)(page);}while(0)
#define kmap_atomic(page, idx) page_address(page)
#define kunmap_atomic(addr, idx) do{} while(0)
#endif
```

## slab分配器

内核必须经常分配内存，但无法借助于标准库的函数。伙伴系统支持按页分配内存，但这个单位太大。如果需要为一个10个字符的字符串分配空间，分配一个4KiB或更多空间的完整页面，不仅浪费而且完全不能接受。

提供小内存不是slab分配器的唯一任务，由于结构上的特点，它也用作一个缓存，主要针对经常分配并释放的对象。

slab分配器还有两个更进一步的好处

- 调用伙伴系统的操作对系统的数据和指令高速缓存有相当的影响
- 通过slab着色，能够均匀分布对象，以实现均匀的缓存利用。(着色表示slab中的对象需要移动的特定偏移量，以便使对象防止到不同的缓存行)

### 备选分配器

两个slab分配器的替代品

- slob分配器进行特别优化，以便减少代码量。它围绕一个简单的内存块链表展开。在分配内存时，使用同样简单的最先适配算法
- slub分配器通过将页帧打包为组，并通过strut page中未使用的字段来管理这些组，试图最小化所需的内存开销。

所有分配器的前端接口都是相同的。每个分配器都必须实现一组特定的函数，用于内存分配和缓存

- kmalloc、__kmalloc和kmalloc_node是一般的内存分配函数
- kmem_cache_alloc、kmem_cache_alloc_node提供特定类型的内核缓存

 ![1575534966(1)](resources\1575534966(1).jpg)

### 内核中的内存管理

内核中一般的内存分配和释放函数与C标准库中等价函数的名称类似，用法也几乎相同。

- kmalloc分配长度为size字节的一个内存区，并返回指向该内存区起始处的一个void指针。如果没有足够内存，则结果为NULL指针
- kfree(*ptr)释放*ptr指向的内存区

内核还包括percpu_alloc和percpu_free函数，用于为各个系统CPU分配和释放所需内存区。

### slab分配的原理

基本上，slab缓存由两部分组成：保存管理性数据的缓存对象和保存被管理对象的各个slab。

 ![1575601874(1)](resources\1575601874(1).jpg)

每个缓存只负责一种对象类型，或提供一般性的缓冲区。系统中所有的缓存都保存在一个双链表中。这使得内核有机会依次遍历所有的缓存。

**1.缓存的精细结构**

缓存结构包括两个特别重要的成员：

- 指向一个数组的指针，其中保存各个CPU最后释放的对象。

- 每个内存结点都对应3个表头，用于组织slab的链表。第1个链表包含完全用尽的slab，第2个是部分空闲的slab，第3个是空闲的slab。

   ![1575602087(1)](resources\1575602087(1).jpg)

对象体系形成三级结构

1. 仍然处于CPU高速缓存的per-CPU对象
2. 现存slab中未使用的对象
3. 刚使用伙伴系统分配的新slab中未使用的对象

**2.slab的精细结构**

对象在slab中并非连续排列，而是按照一个相当复杂的方案分布。

未满足某些对齐方式的要求，有两种可用的备选对齐方案

- slab创建时使用标志SLAB_HWCACHE_ALLGN，slab用于可以要求按硬件缓存行对齐。如果对象小于缓存行长度的一半，那么将多个对象放入一个缓存行。
- 如果不要求按硬件缓存行对齐，那么内核保证对象按BYTES_PER_WORD对齐，该值表示void指针所需字节的数目。

 ![1575602535(1)](resources\1575602535(1).jpg)

填充自己可以加速对slab中对象的访问。如果使用对齐的地址，那么几乎所有的体系结构上，内存访问都会更快。这弥补使用填充字节必然导致需要更多内存的不利情况。

### 实现

由于slab系统带有大量调试选项，所以代码中遍布着预处理器语句

- **危险区** ：在每个对象的开始和结束出增加一个额外的内存区，其中填充已知的字节模式。如果模式被修改，程序员在分析内核内存时注意到，可能某些代码访问了不属于它们的内存区。
- **对象毒化** ：在建立和释放slab时，将对象用预定义的模式填充、如果在对象分配时注意到该模式已经改变，程序员就知道已经发生了未授权访问。

**1.数据结构**

每个缓存由kmem_cache结构的一个实例表示。

```c
struct kmem_cache{
  //  per-CPU数据，在每次分配/释放期间都会访问
    struct array_cache *array[NR_CPUS];

/* 1) 
 *   可调整的缓存参数。由cache_chain_mutex保护  */
    //  要转移本地高速缓存的大批对象的数量
    unsigned int batchcount;
    unsigned int limit;
    //  本地高速缓存中空闲对象的最大数目
    unsigned int shared;

/* 2) 
 *   后端每次分配和释放内存时都会访问 */
    //  描述高速缓存永久属性的一组标志
    unsigned int flags;         /* constant flags */
    //  封装在一个单独slab中的对象个数
    unsigned int num;           /* # of objs per slab */

/* 3) 
 *    缓存的增长/缩减  */
    /* 一个单独slab中包含的连续页框数目的对数*/
    unsigned int gfporder;

    /* 强制的GFP标志，例如GFP_DMA  */
    gfp_t allocflags;

    size_t colour;          /* cache colouring range 缓存着色范围  */
    unsigned int colour_off;    /* colour offset slab中的着色偏移 */
    struct kmem_cache *freelist_cache;
    unsigned int freelist_size;

    /* constructor func 构造函数  */
    void (*ctor)(void *obj);

/* 4) 
 *    缓存创建/删除 */
    const char *name;   //  存放高速缓存名字的字符数组
    struct list_head next;  //  高速缓存描述符双向链表使用的指针

/* 5) statistics
 *    统计量 */
 ...
 
    struct kmem_cache_node *node[MAX_NUMNODES];
}
```

kmem_cache和管理slab所需的全部变量，在填充或清空per-CPU缓存时需要访问这两部分。

- nodelists是一个数组，每个数组项对应于系统中一个可能的内存结点。
- flags是一个标志寄存器，定义缓存的全局性质。当前只有一个标志位。如果管理结构存储在slab外部，则置位CFLGS_OFF_SLAB。
- objsize是缓存中对象的长度，包括用于对齐目的所有填充字节。
- num保存可以放入slab对象的最大数目。
- free_limit指定缓存在收缩之后空闲对象数的上限。

kmem_cache第3部分包含用于增长(和收缩)缓存的所有变量

**2.初始化**

kmem_cache_init函数用于初始化slab分配器。它在内核初始化阶段、伙伴系统启用之后调用。采用一个多步骤过程，逐步激活slab分配器。

1. kmem_cache_init创建系统中的第一个slab缓存，以便为kmalloc的实例提供内存。
2. kmem_cache_init接下来初始化一般性的缓存，用作kmalloc内存的来源。
3. 在kmem_cache_init最后一步，把到现在为止一直使用的数据结构的所有静态实例化的成员，用kmalloc动态分配的版本替换。g_cpucache_up的状态现在是FULL，表示slab分配器已经就绪，可以使用。

**3.创建缓存**

创建新的slab缓存必须调用kmem_cache_create。

创建新缓存是一个冗长的过程，kmem_cache_create的代码流程图如图：

 ![1575876620(1)](resources\1575876620(1).jpg)

**4.分配对象**

kmem_cache_alloc用于从特定的缓存获取对象。代码流程图如下：

 ![1575876817(1)](resources\1575876817(1).jpg)

**5.缓存的增长**

 ![1575876884(1)](resources\1575876884(1).jpg)

**6.释放对象**

如果一个分配的对象已经不再需要，那么必须使用kmem_cache_free返回给slab分配器。

 ![1575876969(1)](resources\1575876969(1).jpg)

### 通用缓存

如果不涉及对象缓存，而是传统意义上的分配/释放内存，则必须调用kmalloc和kfree函数，这两个函数，相当于用户空间中C标准库malloc和free函数的内核等价物。

**1.kmalloc的实现**

kmalloc的基础是一个数组，其中是一些分配用于不同内存长度的slab缓存。数组项是cache_sizes的实例。

```c
struct cache_sizes{
  size_t cs_size;
  kmem_cache_t *cs_cachep;
  kmem_cache_t *cs_dmacachep;
#ifdef CONFIG_ZONE_DMA
	struct kmem_cache *cs_dmacachep;
#endif	
}
```

**2.kfree的实现**

```c
void kfree(const void *objp){
  kmem_cache_t *c;
  unsigned long flags;
  
  if(unlikely(ZERO_OR_NULL_PTR(objp)))
  	return;
  c = virt_to_cache(objp);
  __cache_free(c, (void*)objp);
}
```

在找到与内存指针关联的缓存之后，kfree将实际工作移交__cache_free函数完成。

## 处理器高速缓存和TLB控制

内核中各个特定于CPU的部分都必须提供下列函数，以便控制TLB和高速缓存。

- flush_tlb_all和flush_cache_all刷出整个TLB/高速缓存。
- flush_tlb_mm(struct mm_struct * mm) 和 flush_cache_mm刷出所有属于地址空间mm的TLB/高速缓存项
- flush_tlb_range刷出地址范围vma->vm_mm中虚拟地址start和end之间的所有TLB/高速缓存项
- flush_tlb_page刷出虚拟地址[page, page + PAGE_SIZE]范围内所有的TLB/高速缓存项
- update_mmu_cache在处理页失效之后调用。它在处理器的内存管理单元MMU中加入信息，使得虚拟地址address由页表pte描述。





































